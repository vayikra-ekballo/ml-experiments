{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1igUEWoZG9974U9P25Si6JXxtBH-DxNBg","timestamp":1763190472884}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b0fd83da10174edaa624d35a577e8655":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fce687be684449ecb9e5f311e92f472b","IPY_MODEL_bb5f73c33ccb4be78029f3c0be79b4d9","IPY_MODEL_bf28023f8d3e4007bbe06e97105f978c"],"layout":"IPY_MODEL_f389a56d6c4b4c9ea73bd97b2e947c39"}},"fce687be684449ecb9e5f311e92f472b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a0a845af2d747d185d16d59e3cc71b9","placeholder":"​","style":"IPY_MODEL_d8b2fd1379b342e2b00ffe32f28db42a","value":"Map: 100%"}},"bb5f73c33ccb4be78029f3c0be79b4d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8d830cd1eb54fde8d38ed2eb014d804","max":30686,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0886f082f5b44e0f9a39531f4968f9e3","value":30686}},"bf28023f8d3e4007bbe06e97105f978c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05a1580333af4d76a452a0a0a56f0dd5","placeholder":"​","style":"IPY_MODEL_c540cbc3980c4a3b8ec73b98a202cf8c","value":" 30686/30686 [00:26&lt;00:00, 1623.29 examples/s]"}},"f389a56d6c4b4c9ea73bd97b2e947c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a0a845af2d747d185d16d59e3cc71b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8b2fd1379b342e2b00ffe32f28db42a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8d830cd1eb54fde8d38ed2eb014d804":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0886f082f5b44e0f9a39531f4968f9e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05a1580333af4d76a452a0a0a56f0dd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c540cbc3980c4a3b8ec73b98a202cf8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea85c14ce8794759bb87150869ff60cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7253e72e4313470bb1440621560f6f85","IPY_MODEL_3951b004498d416b9631d032b82c8364","IPY_MODEL_edca42daaaf1494eaf6a92285fd32b71"],"layout":"IPY_MODEL_acc99855e7ab46e79fecac8e21f239af"}},"7253e72e4313470bb1440621560f6f85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76335343e5ba4798ae1b4d23943d0023","placeholder":"​","style":"IPY_MODEL_de4e5a69700140be9379d6bca6067cad","value":"Map: 100%"}},"3951b004498d416b9631d032b82c8364":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c38bd4e0c1b47a19f1d54d8905dedaa","max":4434,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8277fd72a5df4b9aa52466e2acc6d1cc","value":4434}},"edca42daaaf1494eaf6a92285fd32b71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6d202a2483541bb93ade3e9c7bd6118","placeholder":"​","style":"IPY_MODEL_3483795e7fd54c95931c804d81424401","value":" 4434/4434 [00:01&lt;00:00, 2257.64 examples/s]"}},"acc99855e7ab46e79fecac8e21f239af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76335343e5ba4798ae1b4d23943d0023":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de4e5a69700140be9379d6bca6067cad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c38bd4e0c1b47a19f1d54d8905dedaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8277fd72a5df4b9aa52466e2acc6d1cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6d202a2483541bb93ade3e9c7bd6118":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3483795e7fd54c95931c804d81424401":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2e87b9ad3cd45feb6bd422ad594b6b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21bd09a161474c60898c67d7d0293dfd","IPY_MODEL_fd16d786fc83457d96a5c6baa1418664","IPY_MODEL_f0229f9d69c64970bacef50da698f940"],"layout":"IPY_MODEL_538f2ab685584db1bf28fbd76e7decd7"}},"21bd09a161474c60898c67d7d0293dfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85728954cb7e41afa8bb446984cc7382","placeholder":"​","style":"IPY_MODEL_b8115d0fa361480a89283c28f1d06252","value":"Map: 100%"}},"fd16d786fc83457d96a5c6baa1418664":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b796efede1d44babf68fb2885165d5d","max":4701,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3a2e0a2be004a1ab7d649d1c9039e2b","value":4701}},"f0229f9d69c64970bacef50da698f940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8a5b55a94cc40a19a225cfe2883352b","placeholder":"​","style":"IPY_MODEL_215106a85849459386b9c2a2dee41112","value":" 4701/4701 [00:01&lt;00:00, 2340.32 examples/s]"}},"538f2ab685584db1bf28fbd76e7decd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85728954cb7e41afa8bb446984cc7382":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8115d0fa361480a89283c28f1d06252":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b796efede1d44babf68fb2885165d5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3a2e0a2be004a1ab7d649d1c9039e2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8a5b55a94cc40a19a225cfe2883352b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"215106a85849459386b9c2a2dee41112":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d14226a6da0423c999960072ee145a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc255e83c24e43ceaa9da9342c75f75b","IPY_MODEL_84f986088da94840859fb9154e713b2d","IPY_MODEL_b95360f07cca4cf59fe1b1d8aa131b22"],"layout":"IPY_MODEL_2aafd1f918b44800821b848017fda35b"}},"cc255e83c24e43ceaa9da9342c75f75b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1650da2d07c42869754de4aa9c08fc6","placeholder":"​","style":"IPY_MODEL_2d0a0291c7394e11b31219040950b35e","value":"Downloading builder script: "}},"84f986088da94840859fb9154e713b2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04adff44291d4cb4a9c461292f4d50d2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbd991d10cbb4836ab4b7d199ed2b7c7","value":1}},"b95360f07cca4cf59fe1b1d8aa131b22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff593a78ae16429799b3b8b8dc650f10","placeholder":"​","style":"IPY_MODEL_29ca62ac48d948e5a42c886edc1eb2d1","value":" 6.34k/? [00:00&lt;00:00, 532kB/s]"}},"2aafd1f918b44800821b848017fda35b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1650da2d07c42869754de4aa9c08fc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d0a0291c7394e11b31219040950b35e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04adff44291d4cb4a9c461292f4d50d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cbd991d10cbb4836ab4b7d199ed2b7c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff593a78ae16429799b3b8b8dc650f10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29ca62ac48d948e5a42c886edc1eb2d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["To do:\n","\n","\n","1.   Test more hyperparameters to get metrics in 0.9 - HuggingFace Trainer has native support for hyperparameter search using either Optuna, Ray Tune, or Weights & Biases.\n","2.   Data augmentation - use another LLM to do NER categorization of text. and then add that to the training model.\n","\n"],"metadata":{"id":"jRXTyqRIXL04"}},{"cell_type":"code","source":["#!pip install --upgrade transformers\n","!pip install -q transformers datasets seqeval optuna torch tqdm evaluate\n"],"metadata":{"id":"7XUwO3KBXLAN","executionInfo":{"status":"ok","timestamp":1763411528230,"user_tz":480,"elapsed":10766,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlwkpUQKjK60","executionInfo":{"status":"ok","timestamp":1763411593585,"user_tz":480,"elapsed":65349,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}},"outputId":"859c6b12-3f14-4df0-b05e-81ed72ea639a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'NERAncientGreekML4AL'...\n","remote: Enumerating objects: 251, done.\u001b[K\n","remote: Total 251 (delta 0), reused 0 (delta 0), pack-reused 251 (from 3)\u001b[K\n","Receiving objects: 100% (251/251), 106.47 MiB | 2.97 MiB/s, done.\n","Resolving deltas: 100% (98/98), done.\n","Updating files: 100% (199/199), done.\n","Downloading Data/homogenisation/full_dataset_FINAL.csv (113 MB)\n","Error downloading object: Data/homogenisation/full_dataset_FINAL.csv (82d984c): Smudge error: Error downloading Data/homogenisation/full_dataset_FINAL.csv (82d984c506fbdcea63db80edc6d34c42f5128b2de3a34df706c6ecae87f02254): batch response: This repository exceeded its LFS budget. The account responsible for the budget should increase it to restore access.\n","\n","Errors logged to /content/NERAncientGreekML4AL/NERAncientGreekML4AL/.git/lfs/logs/20251117T203313.347080711.log\n","Use `git lfs logs last` to view the log.\n","error: external filter 'git-lfs filter-process' failed\n","fatal: Data/homogenisation/full_dataset_FINAL.csv: smudge filter lfs failed\n","warning: Clone succeeded, but checkout failed.\n","You can inspect what was checked out with 'git status'\n","and retry with 'git restore --source=HEAD :/'\n","\n","/content/NERAncientGreekML4AL/NERAncientGreekML4AL\n","final_dataset/normal/test.conll   final_dataset/normal/val.conll\n","final_dataset/normal/train.conll\n"]}],"source":["\n","\n","# Clone the repo\n","!git clone https://github.com/NER-AncientLanguages/NERAncientGreekML4AL.git\n","%cd NERAncientGreekML4AL\n","\n","# Verify data exists\n","!ls final_dataset/normal/*.conll"]},{"cell_type":"code","source":["import os, warnings, unicodedata, numpy as np\n","from pathlib import Path\n","from datasets import Dataset, DatasetDict\n","from transformers import (\n","    AutoTokenizer, AutoModelForTokenClassification,\n","    TrainingArguments, Trainer, DataCollatorForTokenClassification\n",")\n","\n","def read_conll(p: Path):\n","    \"\"\"\n","    Parse CoNLL with format:\n","        [line_id]  token  [POS]  NER\n","    Example:\n","        110089790\tβίβλος\tO\n","    Returns: {\"tokens\": [...], \"ner_tags\": [...]}\n","    \"\"\"\n","    sents, labs = [], []\n","    with p.open(encoding=\"utf-8\") as f:\n","        sent, lab = [], []\n","        for i, raw in enumerate(f, 1):\n","            line = raw.strip()\n","            if not line or line.startswith(\"#\"):\n","                if sent:\n","                    sents.append(sent)\n","                    labs.append(lab)\n","                    sent, lab = [], []\n","                continue\n","\n","            # Split on whitespace (handles tabs and spaces)\n","            parts = line.split()\n","            if len(parts) < 2:\n","                print(f\"Warning: Line {i} in {p.name} has <2 columns → SKIPPED\")\n","                print(f\"    → {line!r}\")\n","                continue\n","\n","            if len(parts) == 2:\n","                token = parts[0]\n","                ner   = parts[1]\n","            else:\n","                token = parts[1]   # skip ID\n","                ner   = parts[-1]  # last column is NER\n","\n","            sent.append(unicodedata.normalize(\"NFC\", token))\n","            lab.append(ner)\n","\n","        if sent:\n","            sents.append(sent)\n","            labs.append(lab)\n","\n","    print(f\"Loaded {len(sents)} sentences from {p.name}\")\n","    return {\"tokens\": sents, \"ner_tags\": labs}\n","\n","# load data\n","train_path = Path(\"final_dataset/normal/train.conll\")\n","val_path   = Path(\"final_dataset/normal/val.conll\")\n","test_path  = Path(\"final_dataset/normal/test.conll\")\n","\n","raw = {\n","    \"train\": read_conll(train_path),\n","    \"validation\": read_conll(val_path),\n","    \"test\": read_conll(test_path),\n","}\n","data = DatasetDict({k: Dataset.from_dict(v) for k, v in raw.items()})\n","\n","#Model name -------------------------------------------------------------\n","model_name = \"Marijke/AG_BERT_hypopt_NER\"\n","tokenizer  = AutoTokenizer.from_pretrained(model_name)\n","#------------------------------------------------------------------------\n","\n","all_labels = sorted({l for s in data[\"train\"][\"ner_tags\"] for l in s})\n","label2id   = {l: i for i, l in enumerate(all_labels)}\n","id2label   = {i: l for l, i in label2id.items()}\n","\n","#tokenise + align labels\n","def tokenise_align(example):\n","    tok = tokenizer(example[\"tokens\"], truncation=True, is_split_into_words=True)\n","    aligned = []\n","    for i, labs in enumerate(example[\"ner_tags\"]):\n","        word_ids = tok.word_ids(batch_index=i)\n","        prev = None\n","        ids  = []\n","        for wid in word_ids:\n","            if wid is None:\n","                ids.append(-100)\n","            elif wid != prev:\n","                ids.append(label2id[labs[wid]])\n","            else:\n","                ids.append(-100)               # sub-word → ignore\n","            prev = wid\n","        aligned.append(ids)\n","    tok[\"labels\"] = aligned\n","    return tok\n","\n","tokenised = data.map(tokenise_align, batched=True,\n","                     remove_columns=data[\"train\"].column_names)\n","\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(all_labels),\n","    id2label=id2label,\n","    label2id=label2id,\n",")\n","\n","collator = DataCollatorForTokenClassification(tokenizer)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167,"referenced_widgets":["b0fd83da10174edaa624d35a577e8655","fce687be684449ecb9e5f311e92f472b","bb5f73c33ccb4be78029f3c0be79b4d9","bf28023f8d3e4007bbe06e97105f978c","f389a56d6c4b4c9ea73bd97b2e947c39","1a0a845af2d747d185d16d59e3cc71b9","d8b2fd1379b342e2b00ffe32f28db42a","b8d830cd1eb54fde8d38ed2eb014d804","0886f082f5b44e0f9a39531f4968f9e3","05a1580333af4d76a452a0a0a56f0dd5","c540cbc3980c4a3b8ec73b98a202cf8c","ea85c14ce8794759bb87150869ff60cf","7253e72e4313470bb1440621560f6f85","3951b004498d416b9631d032b82c8364","edca42daaaf1494eaf6a92285fd32b71","acc99855e7ab46e79fecac8e21f239af","76335343e5ba4798ae1b4d23943d0023","de4e5a69700140be9379d6bca6067cad","0c38bd4e0c1b47a19f1d54d8905dedaa","8277fd72a5df4b9aa52466e2acc6d1cc","d6d202a2483541bb93ade3e9c7bd6118","3483795e7fd54c95931c804d81424401","e2e87b9ad3cd45feb6bd422ad594b6b1","21bd09a161474c60898c67d7d0293dfd","fd16d786fc83457d96a5c6baa1418664","f0229f9d69c64970bacef50da698f940","538f2ab685584db1bf28fbd76e7decd7","85728954cb7e41afa8bb446984cc7382","b8115d0fa361480a89283c28f1d06252","4b796efede1d44babf68fb2885165d5d","d3a2e0a2be004a1ab7d649d1c9039e2b","e8a5b55a94cc40a19a225cfe2883352b","215106a85849459386b9c2a2dee41112"]},"id":"M48lINeotYTu","executionInfo":{"status":"ok","timestamp":1763411651819,"user_tz":480,"elapsed":58233,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}},"outputId":"84658c72-24d2-456d-883b-7ffdb6bd147e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 30686 sentences from train.conll\n","Loaded 4434 sentences from val.conll\n","Loaded 4701 sentences from test.conll\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/30686 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0fd83da10174edaa624d35a577e8655"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4434 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea85c14ce8794759bb87150869ff60cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4701 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2e87b9ad3cd45feb6bd422ad594b6b1"}},"metadata":{}}]},{"cell_type":"code","source":["import evaluate\n","from seqeval.metrics import classification_report\n","\n","def compute_metrics(p):\n","    preds, labels = p\n","    preds = np.argmax(preds, axis=2)\n","\n","    true_labels = []\n","    pred_labels = []\n","\n","    for prediction, label in zip(preds, labels):\n","        true_seq = [id2label[l] for l in label if l != -100]\n","        pred_seq = [id2label[pred] for pred, l in zip(prediction, label) if l != -100]\n","        if true_seq:  # Only add if not empty\n","            true_labels.append(true_seq)\n","            pred_labels.append(pred_seq)\n","\n","    if not true_labels:\n","        return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n","\n","\n","    metric = evaluate.load(\"seqeval\")\n","    results = metric.compute(predictions=pred_labels, references=true_labels)\n","    print(results)\n","\n","    return {\n","      \"precision\": results[\"overall_precision\"],\n","      \"recall\": results['overall_recall'],\n","      \"f1\": results[\"overall_f1\"]\n","    }\n","\n"],"metadata":{"id":"77nBByjh5sF3","executionInfo":{"status":"ok","timestamp":1763411652294,"user_tz":480,"elapsed":467,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# Hyper-parameters\n","# ------------------------------------------------------------\n","LEARNING_RATE = 3e-5\n","BATCH_SIZE    = 16\n","EPOCHS        = 5\n","WEIGHT_DECAY  = 0.01\n","WARMUP_RATIO  = 0.06\n","SEED          = 123\n","OUTPUT_DIR    = \"./tuned_ner_model\"\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=LEARNING_RATE,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    num_train_epochs=EPOCHS,\n","    weight_decay=WEIGHT_DECAY,\n","    warmup_ratio=WARMUP_RATIO,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    seed=SEED,\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to=[],\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenised[\"train\"],\n","    eval_dataset=tokenised[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","#Train the model\n","print(\"\\nSTARTING TRAINING ...\\n\")\n","trainer.train()\n","\n","#Save the model\n","trainer.save_model(OUTPUT_DIR)\n","tokenizer.save_pretrained(OUTPUT_DIR)\n","print(f\"\\nModel saved to {OUTPUT_DIR}\")\n","\n"],"metadata":{"id":"oTOvrHmvzdwG","colab":{"base_uri":"https://localhost:8080/","height":266,"referenced_widgets":["9d14226a6da0423c999960072ee145a3","cc255e83c24e43ceaa9da9342c75f75b","84f986088da94840859fb9154e713b2d","b95360f07cca4cf59fe1b1d8aa131b22","2aafd1f918b44800821b848017fda35b","c1650da2d07c42869754de4aa9c08fc6","2d0a0291c7394e11b31219040950b35e","04adff44291d4cb4a9c461292f4d50d2","cbd991d10cbb4836ab4b7d199ed2b7c7","ff593a78ae16429799b3b8b8dc650f10","29ca62ac48d948e5a42c886edc1eb2d1"]},"outputId":"363eabdd-b474-464d-e403-cd75e72a5039"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-267916977.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"stream","name":"stdout","text":["\n","STARTING TRAINING ...\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3181' max='9590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3181/9590 13:42 < 27:37, 3.87 it/s, Epoch 1.66/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.039900</td>\n","      <td>0.096823</td>\n","      <td>0.822140</td>\n","      <td>0.832586</td>\n","      <td>0.827330</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d14226a6da0423c999960072ee145a3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'GRP': {'precision': np.float64(0.8094170403587444), 'recall': np.float64(0.838884585592564), 'f1': np.float64(0.8238874096614682), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.7127583749109052), 'recall': np.float64(0.7434944237918215), 'f1': np.float64(0.727802037845706), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8644025780862667), 'recall': np.float64(0.8601381351751357), 'f1': np.float64(0.8622650840751731), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.822140221402214), 'overall_recall': np.float64(0.8325859491778774), 'overall_f1': np.float64(0.8273301151132566), 'overall_accuracy': 0.9771520316166481}\n"]}]},{"cell_type":"code","source":["#Quick test\n","from transformers import pipeline\n","import unicodedata\n","\n","ner = pipeline(\"ner\", model=OUTPUT_DIR, tokenizer=OUTPUT_DIR,\n","               aggregation_strategy=\"simple\")\n","\n","txt = unicodedata.normalize(\"NFC\", \"\"\"\n","  ᾿Ανέστη δὲ βασιλεὺς ἕτερος ἐπ᾿ Αἴγυπτον, ὃς οὐκ ᾔδει τὸν ᾿Ιωσήφ.\n","  εἶπε δὲ τῷ ἔθνει αὐτοῦ· ἰδοὺ τὸ γένος τῶν υἱῶν ᾿Ισραὴλ μέγα πλῆθος καὶ ἰσχύει ὑπὲρ ἡμᾶς·\n","  δεῦτε οὖν κατασοφισώμεθα αὐτούς, μή ποτε πληθυνθῇ, καὶ ἡνίκα ἂν συμβῇ ἡμῖν πόλεμος,\n","  προστεθήσονται καὶ οὗτοι πρὸς τοὺς ὑπεναντίους καὶ ἐκπολεμήσαντες ἡμᾶς ἐξελεύσονται ἐκ τῆς γῆς.\n","  καὶ ἐπέστησεν αὐτοῖς ἐπιστάτας τῶν ἔργων, ἵνα κακώσωσιν αὐτοὺς ἐν τοῖς ἔργοις· καὶ Ισραήλᾠκοδόμησαν πόλεις ὀχυρὰς τῷ Φαραώ, τήν τε Πειθὼ καὶ Ῥαμεσσῆ καὶ ῎Ων, ἥ ἐστιν ῾Ηλιούπολις.\n","  καθότι δὲ αὐτοὺς ἐταπείνουν, τοσούτῳ πλείους ἐγίγνοντο, καὶ ἴσχυον σφόδρα σφόδρα· καὶ ἐβδελύσσοντο οἱ Αἰγύπτιοι ἀπὸ τῶν υἱῶν ᾿.\n","  καὶ κατεδυνάστευον οἱ Αἰγύπτιοι τοὺς υἱοὺς ᾿Ισραὴλ βίᾳ καὶ κατωδύνων αὐτῶν τὴν ζωὴν ἐν τοῖς ἔργοις τοῖς σκληροῖς, τῷ πηλῷ καὶ τῇ πλινθείᾳ καὶ πᾶσι τοῖς ἔργοις τοῖς ἐν τοῖς πεδίοις, κατὰ πάντα τὰ ἔργα, ὧν κατεδουλοῦντο αὐτοὺς μετὰ βίας.\n","\"\"\")\n","\n","merged_results = []\n","\n","for r in ner(txt):\n","    if r['word'].startswith(\"##\"):\n","        merged_results[-1]['word'] += r['word'][2:]  # remove ## and join the subwords together instead of splitting it\n","        merged_results[-1]['score'] = max(merged_results[-1]['score'], r['score'])\n","    else:\n","        merged_results.append(r)\n","\n","for r in merged_results:\n","    print(f\"{r['word']:<20} → {r['entity_group']:<6} ({r['score']:.3f})\")\n"],"metadata":{"id":"expUuoIklEdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# Hyper-parameters\n","# ------------------------------------------------------------\n","LEARNING_RATE = 3e-5\n","BATCH_SIZE    = 32\n","EPOCHS        = 5\n","WEIGHT_DECAY  = 0.01\n","WARMUP_RATIO  = 1.0\n","SEED          = 123\n","OUTPUT_DIR    = f\"./tuned_ner_model_lr{LEARNING_RATE}_bs{BATCH_SIZE}_ep{EPOCHS}\"\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=LEARNING_RATE,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    num_train_epochs=EPOCHS,\n","    weight_decay=WEIGHT_DECAY,\n","    warmup_ratio=WARMUP_RATIO,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    seed=SEED,\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to=[],\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenised[\"train\"],\n","    eval_dataset=tokenised[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"metadata":{"id":"kyHhVrMr_yxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Zero-shot transfer:  Due to its nature that the ground\n","truth label exists at word level, supervised training of NER models often requires large amount\n","of human annotation efforts. In real-world use\n","cases where one needs to build multi-lingual models, the required human labor scales at least linearly with number of languages, or even worse\n","for low resource languages. Li, B., He, Y., & Xu, W. (2021). Cross-Lingual Named Entity Recognition Using Parallel Corpus: A New Approach Using XLM-RoBERTa Alignment. arXiv\n","https://arxiv.org/pdf/2101.11112\n","\n"],"metadata":{"id":"8k9KQBAk0rhh"}},{"cell_type":"code","source":["# https://huggingface.co/datasets/hmcgovern/original-language-bibles-greek\n","import pandas as pd\n","\n","dataset_hf_path = '/content/drive/MyDrive/Deep Learning Group Project/train-00000-of-00001.parquet'\n","dataset_hf = pd.read_parquet(dataset_hf_path)\n","dataset_hf.head(10)\n","len(dataset_hf)"],"metadata":{"id":"G-WPgchqqijy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import joblib\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from transformers import pipeline\n","from datasets import Dataset\n","\n","# ----- SETTINGS -----\n","CACHE_FILE     = \"/content/drive/MyDrive/Deep Learning Group Project/ner_labels_wordlevel.pkl.gz\"\n","CSV_OUT_FILE   = \"/content/drive/MyDrive/Deep Learning Group Project/ner_labels.csv\"\n","WORDS_PER_BATCH = 64          # how many *words* to join into one fake sentence since the dataset is on word\n","HF_BATCH_SIZE   = 64          # pipeline internal batch size (sentences)\n","# -------------------------\n","\n","device = 0 if torch.cuda.is_available() else -1\n","print(f\"NER device: {'GPU' if device == 0 else 'CPU'}\")\n","\n","ner_model = pipeline(\n","    \"ner\",\n","    model=\"dslim/bert-base-NER\",\n","    aggregation_strategy=\"simple\",\n","    device=device,\n","    batch_size=HF_BATCH_SIZE,\n",")\n","\n","def ner_on_word_batch(word_list):\n","    if not word_list:\n","        return []\n","\n","    fake_sentence = \" \".join(word_list)\n","    entities = ner_model(fake_sentence)\n","    labels = [\"O\"] * len(word_list)\n","\n","    char_pos = 0\n","    for ent in entities:\n","        ent_start = ent[\"start\"]\n","        ent_label = ent[\"entity_group\"]\n","\n","        word_idx = 0\n","        current_pos = 0\n","        while word_idx < len(word_list):\n","            word_len = len(word_list[word_idx])\n","            if current_pos <= ent_start < current_pos + word_len:\n","                labels[word_idx] = ent_label\n","                break\n","            current_pos += word_len + 1\n","            word_idx += 1\n","\n","    return labels\n","\n","if os.path.exists(CACHE_FILE):\n","    print(f\"Loading cached NER labels from:\\n    {CACHE_FILE}\")\n","    final_labels = joblib.load(CACHE_FILE)\n","else:\n","    print(f\"Cache missing → running batched NER on {len(dataset_hf)} words...\")\n","    final_labels = []\n","\n","    words = dataset_hf[\"translation\"].tolist()\n","\n","    for i in tqdm(range(0, len(words), WORDS_PER_BATCH),\n","                  desc=\"NER word batches\",\n","                  total=(len(words) + WORDS_PER_BATCH - 1) // WORDS_PER_BATCH):\n","\n","        batch_words = words[i:i + WORDS_PER_BATCH]\n","        batch_labels = ner_on_word_batch(batch_words)\n","        final_labels.extend(batch_labels)\n","\n","\n","    os.makedirs(os.path.dirname(CACHE_FILE), exist_ok=True)\n","    print(f\"Saving {len(final_labels)} labels → {CACHE_FILE}\")\n","    joblib.dump(final_labels, CACHE_FILE, compress=(\"gzip\", 3))\n","\n","dataset_hf = dataset_hf.assign(ner_label=final_labels)\n","\n","os.makedirs(os.path.dirname(CSV_OUT_FILE), exist_ok=True)\n","dataset_hf[[\"text\", \"translation\", \"ner_label\"]].to_csv(CSV_OUT_FILE, index=False)\n","print(f\"CSV saved: {CSV_OUT_FILE}\")\n"],"metadata":{"id":"ppFzhNtszAWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"zXs679rH37zo"}},{"cell_type":"code","source":["### 1. Need to convert the ner label to BIO format first\n","### 2. Join the new dataset to the existing trainingdata\n","\n","\n","from datasets import concatenate_datasets\n","import os\n","\n","print(f\"Original train rows: {len(data['train'])}\")\n","print(f\"Original train features: {data['train'].features}\")\n","\n","from datasets import Features, Value, Sequence\n","\n","new_dataset = Dataset.from_dict({\n","    \"tokens\": dataset_hf[\"text\"].tolist(),\n","    \"ner_tags\": dataset_hf[\"ner_label\"].tolist(),\n","})\n","print(new_dataset)\n","\n","expected_features = Features({\n","    \"tokens\": Sequence(Value(\"string\")),\n","    \"ner_tags\": Value(\"string\"),\n","})\n","\n","print(f\"Adding {len(new_dataset)} NER examples to train...\")\n","data[\"train\"] = concatenate_datasets([data[\"train\"], new_dataset])\n","\n","print(f\"New train size: {len(data['train'])} rows\")\n","\n","print(\"Tokenizing full train split...\")\n","tokenised_train = data[\"train\"].map(\n","    tokenise_align,\n","    batched=True,\n","    num_proc=os.cpu_count(),\n","    batch_size=2000,\n","    remove_columns=data[\"train\"].column_names,  # keep only tokenizer outputs\n",")\n","\n","data[\"train\"] = tokenised_train\n","\n","\n","print(f\"Tokenization complete!\")\n","print(f\"Final train rows: {len(data['train'])}\")\n","print(f\"Final columns: {data['train'].column_names}\")\n","print(f\"Example: {data['train'][0].keys()}\")"],"metadata":{"id":"qZDRFZ8u_y6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#and then save it for future training\n","def save_hf_dataset_to_conll(dataset, output_file):\n","\n","    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n","        for example in dataset:\n","            tokens = example[\"tokens\"]\n","            labels = example[\"ner_tags\"]\n","\n","            for token, label in zip(tokens, labels):\n","                f.write(f\"{token}\\t{label}\\n\")  # tab-separated\n","            f.write(\"\\n\")  # sentence boundary\n","\n","# Example: convert train split\n","save_hf_dataset_to_conll(dataset_hf[\"train\"], \"train_from_hf.conll\")\n","save_hf_dataset_to_conll(dataset_hf[\"test\"], \"test_from_hf.conll\")\n","\n"],"metadata":{"id":"3gKX7f0m_y9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8Xyv3sFM_zAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# Hyper-parameters\n","# ------------------------------------------------------------\n","LEARNING_RATE = 3e-5\n","BATCH_SIZE    = 32\n","EPOCHS        = 10\n","WEIGHT_DECAY  = 0.001\n","WARMUP_RATIO  = 0.6\n","SEED          = 123\n","OUTPUT_DIR    = f\"./tuned_ner_model_lr{LEARNING_RATE}_bs{BATCH_SIZE}_ep{EPOCHS}\"\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=LEARNING_RATE,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    num_train_epochs=EPOCHS,\n","    weight_decay=WEIGHT_DECAY,\n","    warmup_ratio=WARMUP_RATIO,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    seed=SEED,\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to=[],\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenised[\"train\"],\n","    eval_dataset=tokenised[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"metadata":{"id":"M73F4XjH_zDT"},"execution_count":null,"outputs":[]}]}
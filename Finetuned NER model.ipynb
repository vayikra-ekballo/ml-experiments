{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1igUEWoZG9974U9P25Si6JXxtBH-DxNBg","timestamp":1763190472884}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"84ce2ae968234bb5a0d9607e4f3c9df8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30a6493d641f4440be92bf29a188f815","IPY_MODEL_f7b17de316934570a773e51bb31f4823","IPY_MODEL_945432ac1ec547269baf1b8b048d7004"],"layout":"IPY_MODEL_e5460747cc8a4769ad2871a54658ab1b"}},"30a6493d641f4440be92bf29a188f815":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9adee0542264abfa0bfd5ae385e32d4","placeholder":"​","style":"IPY_MODEL_285e99558f9044c5a511780789ec976f","value":"Downloading builder script: "}},"f7b17de316934570a773e51bb31f4823":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff35bfcdcc664b8aa23a3f2ce0248a95","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57ea40b53c8b4fb4986f0c022db4af29","value":1}},"945432ac1ec547269baf1b8b048d7004":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c88d314d8f014d529c505d147ec3e082","placeholder":"​","style":"IPY_MODEL_12e63314a9d44c7186196139ac6241b5","value":" 6.34k/? [00:00&lt;00:00, 649kB/s]"}},"e5460747cc8a4769ad2871a54658ab1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9adee0542264abfa0bfd5ae385e32d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"285e99558f9044c5a511780789ec976f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff35bfcdcc664b8aa23a3f2ce0248a95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"57ea40b53c8b4fb4986f0c022db4af29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c88d314d8f014d529c505d147ec3e082":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12e63314a9d44c7186196139ac6241b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29458f69f2af4390bf4062aa48b5f432":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb2d74a3054e4495acf7d82f16569e63","IPY_MODEL_a2179aba77564755a04a81e53043f4af","IPY_MODEL_294cf2daa7114d5d90f2d25d5582af2c"],"layout":"IPY_MODEL_519d12157573471dab2b4e52bdff0457"}},"eb2d74a3054e4495acf7d82f16569e63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e26ab1a6d6c4847ab0afdb121abedfb","placeholder":"​","style":"IPY_MODEL_ec4dd203fa504684811eab72e3657731","value":"config.json: 100%"}},"a2179aba77564755a04a81e53043f4af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2c7a27267ef465ab9df3e387dc35e7c","max":829,"min":0,"orientation":"horizontal","style":"IPY_MODEL_276df0fde8224ecbafd5c7a895862fd5","value":829}},"294cf2daa7114d5d90f2d25d5582af2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0e2e75984e94a4bafb655ffc063792e","placeholder":"​","style":"IPY_MODEL_b26e25fbdb9a42e7b88501026808fda9","value":" 829/829 [00:00&lt;00:00, 116kB/s]"}},"519d12157573471dab2b4e52bdff0457":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e26ab1a6d6c4847ab0afdb121abedfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec4dd203fa504684811eab72e3657731":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2c7a27267ef465ab9df3e387dc35e7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"276df0fde8224ecbafd5c7a895862fd5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0e2e75984e94a4bafb655ffc063792e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b26e25fbdb9a42e7b88501026808fda9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"081276e05a114cbab065894a52874a81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b44891e471ec4cba9f9680329f90ef19","IPY_MODEL_4a06f823d61f42ee8ec6ed7370ea327f","IPY_MODEL_3bcc208ad33c481f9363952cd8e524de"],"layout":"IPY_MODEL_468e11e3d8924ed6a8559a717c561c28"}},"b44891e471ec4cba9f9680329f90ef19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c3593eb608b47c09ad13a9c54f910e5","placeholder":"​","style":"IPY_MODEL_04bec223570647e181fee9dc44f4ab92","value":"model.safetensors: 100%"}},"4a06f823d61f42ee8ec6ed7370ea327f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba3199b9a6aa4c7c8dda4ce83ceb4d63","max":433292294,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ceed661f97f74d96a73407370fdf3493","value":433292294}},"3bcc208ad33c481f9363952cd8e524de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75417d7e195045129dc96c7f706cd139","placeholder":"​","style":"IPY_MODEL_3b892715505b42099005a4786ebb13b1","value":" 433M/433M [00:01&lt;00:00, 399MB/s]"}},"468e11e3d8924ed6a8559a717c561c28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c3593eb608b47c09ad13a9c54f910e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04bec223570647e181fee9dc44f4ab92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba3199b9a6aa4c7c8dda4ce83ceb4d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceed661f97f74d96a73407370fdf3493":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75417d7e195045129dc96c7f706cd139":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b892715505b42099005a4786ebb13b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae53fbb4dce84c0199e7aa323406a0ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42756ae0205649adbdd90c3eb3ec5e4c","IPY_MODEL_82c7d8836afa4d39abed176268ee05d9","IPY_MODEL_dbba4bfe9f5f4347872f3f22ed14080a"],"layout":"IPY_MODEL_ee703f78c153450ca46c72fbc949e35e"}},"42756ae0205649adbdd90c3eb3ec5e4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5572a8435ddd40cfbaf06178314bf083","placeholder":"​","style":"IPY_MODEL_48a2f2fc037a4f2c9c708eddb3ef4e5d","value":"tokenizer_config.json: 100%"}},"82c7d8836afa4d39abed176268ee05d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_01b5b70e6aa54ea8be2df0a2128df3a7","max":59,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad84f90562a047cfac9b4ecd69699651","value":59}},"dbba4bfe9f5f4347872f3f22ed14080a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5613e3d6eb4648a7af840dd676f4e987","placeholder":"​","style":"IPY_MODEL_a0140e3226484c989c7a1c8cc8abcd91","value":" 59.0/59.0 [00:00&lt;00:00, 8.30kB/s]"}},"ee703f78c153450ca46c72fbc949e35e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5572a8435ddd40cfbaf06178314bf083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48a2f2fc037a4f2c9c708eddb3ef4e5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01b5b70e6aa54ea8be2df0a2128df3a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad84f90562a047cfac9b4ecd69699651":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5613e3d6eb4648a7af840dd676f4e987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0140e3226484c989c7a1c8cc8abcd91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f1b17157c37499781615fc9f11e2dd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d54061c959a4cdb8b143b57736bf6f3","IPY_MODEL_0f6b56436bbd417290289223e1b2f473","IPY_MODEL_67f4170c0133425e98c61d9f4904cb63"],"layout":"IPY_MODEL_f2f25c89861840f39cd8e8e864e892d5"}},"6d54061c959a4cdb8b143b57736bf6f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1a17ba7e93245a9b0ccc7be05d4a510","placeholder":"​","style":"IPY_MODEL_4638323a83bd4c7dbe3816eee507fb80","value":"vocab.txt: "}},"0f6b56436bbd417290289223e1b2f473":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcac406c115e4b278f61694adf6a8b4b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b231be8fffea41048477e619fe6d7e5b","value":1}},"67f4170c0133425e98c61d9f4904cb63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c830a483c2be4e59b0699c0ac753eec9","placeholder":"​","style":"IPY_MODEL_bd1da9a661fc43ab83df00041141b936","value":" 213k/? [00:00&lt;00:00, 12.6MB/s]"}},"f2f25c89861840f39cd8e8e864e892d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1a17ba7e93245a9b0ccc7be05d4a510":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4638323a83bd4c7dbe3816eee507fb80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcac406c115e4b278f61694adf6a8b4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b231be8fffea41048477e619fe6d7e5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c830a483c2be4e59b0699c0ac753eec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd1da9a661fc43ab83df00041141b936":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"402bb9d1315a4875b80576a9b9d56eaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d452f19141a4d61a3225435cff91192","IPY_MODEL_88389f4a4e614c849677160f42136249","IPY_MODEL_f6ce3ad89d2c4ac98d55247d4efe39e8"],"layout":"IPY_MODEL_ce7fb0bfeefe479c9608930b72853d44"}},"1d452f19141a4d61a3225435cff91192":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dc01d7a0357497592b684df8d90bd9a","placeholder":"​","style":"IPY_MODEL_daa802996bd1471d850779dc99096cb6","value":"added_tokens.json: 100%"}},"88389f4a4e614c849677160f42136249":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda506f61d744ca9bf665652a7fb2fab","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d2c3d5a380e4d55948f539c7c688abb","value":2}},"f6ce3ad89d2c4ac98d55247d4efe39e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45c51ae7e6754fb098880117f781435d","placeholder":"​","style":"IPY_MODEL_dd87f24abde44c3e95002339db09e1df","value":" 2.00/2.00 [00:00&lt;00:00, 271B/s]"}},"ce7fb0bfeefe479c9608930b72853d44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dc01d7a0357497592b684df8d90bd9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"daa802996bd1471d850779dc99096cb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eda506f61d744ca9bf665652a7fb2fab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d2c3d5a380e4d55948f539c7c688abb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45c51ae7e6754fb098880117f781435d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd87f24abde44c3e95002339db09e1df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6342b119fc9d4820b1a895a71f8c44db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c8baee0ad51412d8b358bc6b61a63f7","IPY_MODEL_bd05467771564315837d3a6b35a299df","IPY_MODEL_329e056267b94340ac3f253333a8b7ce"],"layout":"IPY_MODEL_9e4a02322c0847bf9f3c53558057a375"}},"7c8baee0ad51412d8b358bc6b61a63f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e83788175aa46f4a9e3f10ceaaa7d69","placeholder":"​","style":"IPY_MODEL_89aa1234c0834ccab2e8274bb2f992d8","value":"special_tokens_map.json: 100%"}},"bd05467771564315837d3a6b35a299df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_688f805c26ef41dbbfa57f2c340670a5","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8460785098548f7af2713ca3bd9d50e","value":112}},"329e056267b94340ac3f253333a8b7ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e60505abda5f4bd2b307c36edb71df59","placeholder":"​","style":"IPY_MODEL_205dc5f8fc67464587f0ef45e0a90ee1","value":" 112/112 [00:00&lt;00:00, 14.8kB/s]"}},"9e4a02322c0847bf9f3c53558057a375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e83788175aa46f4a9e3f10ceaaa7d69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89aa1234c0834ccab2e8274bb2f992d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"688f805c26ef41dbbfa57f2c340670a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8460785098548f7af2713ca3bd9d50e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e60505abda5f4bd2b307c36edb71df59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"205dc5f8fc67464587f0ef45e0a90ee1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["To do:\n","\n","\n","1.   Test more hyperparameters to get metrics in 0.9 - HuggingFace Trainer has native support for hyperparameter search using either Optuna, Ray Tune, or Weights & Biases.\n","2.   Data augmentation - use another LLM to do NER categorization of text. and then add that to the training model.\n","\n"],"metadata":{"id":"jRXTyqRIXL04"}},{"cell_type":"code","source":[],"metadata":{"id":"7XUwO3KBXLAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlwkpUQKjK60","executionInfo":{"status":"ok","timestamp":1763398895827,"user_tz":300,"elapsed":49429,"user":{"displayName":"Javier Marsicano","userId":"11865106587474936769"}},"outputId":"f31d019a-4f57-497c-90b2-ffeeeeb78dd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'NERAncientGreekML4AL'...\n","remote: Enumerating objects: 251, done.\u001b[K\n","remote: Total 251 (delta 0), reused 0 (delta 0), pack-reused 251 (from 3)\u001b[K\n","Receiving objects: 100% (251/251), 106.47 MiB | 6.07 MiB/s, done.\n","Resolving deltas: 100% (98/98), done.\n","Updating files: 100% (199/199), done.\n","Downloading Data/homogenisation/full_dataset_FINAL.csv (113 MB)\n","Error downloading object: Data/homogenisation/full_dataset_FINAL.csv (82d984c): Smudge error: Error downloading Data/homogenisation/full_dataset_FINAL.csv (82d984c506fbdcea63db80edc6d34c42f5128b2de3a34df706c6ecae87f02254): batch response: This repository exceeded its LFS budget. The account responsible for the budget should increase it to restore access.\n","\n","Errors logged to /content/NERAncientGreekML4AL/NERAncientGreekML4AL/.git/lfs/logs/20251117T170135.44429968.log\n","Use `git lfs logs last` to view the log.\n","error: external filter 'git-lfs filter-process' failed\n","fatal: Data/homogenisation/full_dataset_FINAL.csv: smudge filter lfs failed\n","warning: Clone succeeded, but checkout failed.\n","You can inspect what was checked out with 'git status'\n","and retry with 'git restore --source=HEAD :/'\n","\n","/content/NERAncientGreekML4AL/NERAncientGreekML4AL\n","final_dataset/normal/test.conll   final_dataset/normal/val.conll\n","final_dataset/normal/train.conll\n"]}],"source":["!pip install -q transformers datasets seqeval optuna torch tqdm evaluate\n","\n","# Clone the repo\n","!git clone https://github.com/NER-AncientLanguages/NERAncientGreekML4AL.git\n","%cd NERAncientGreekML4AL\n","\n","# Verify data exists\n","!ls final_dataset/normal/*.conll"]},{"cell_type":"code","source":["import os, warnings, unicodedata, numpy as np\n","from pathlib import Path\n","from datasets import Dataset, DatasetDict\n","from transformers import (\n","    AutoTokenizer, AutoModelForTokenClassification,\n","    TrainingArguments, Trainer, DataCollatorForTokenClassification\n",")\n","\n","def read_conll(p: Path):\n","    \"\"\"\n","    Parse CoNLL with format:\n","        [line_id]  token  [POS]  NER\n","    Example:\n","        110089790\tβίβλος\tO\n","    Returns: {\"tokens\": [...], \"ner_tags\": [...]}\n","    \"\"\"\n","    sents, labs = [], []\n","    with p.open(encoding=\"utf-8\") as f:\n","        sent, lab = [], []\n","        for i, raw in enumerate(f, 1):\n","            line = raw.strip()\n","            if not line or line.startswith(\"#\"):\n","                if sent:\n","                    sents.append(sent)\n","                    labs.append(lab)\n","                    sent, lab = [], []\n","                continue\n","\n","            # Split on whitespace (handles tabs and spaces)\n","            parts = line.split()\n","            if len(parts) < 2:\n","                print(f\"Warning: Line {i} in {p.name} has <2 columns → SKIPPED\")\n","                print(f\"    → {line!r}\")\n","                continue\n","\n","            if len(parts) == 2:\n","                token = parts[0]\n","                ner   = parts[1]\n","            else:\n","                token = parts[1]   # skip ID\n","                ner   = parts[-1]  # last column is NER\n","\n","            sent.append(unicodedata.normalize(\"NFC\", token))\n","            lab.append(ner)\n","\n","        if sent:\n","            sents.append(sent)\n","            labs.append(lab)\n","\n","    print(f\"Loaded {len(sents)} sentences from {p.name}\")\n","    return {\"tokens\": sents, \"ner_tags\": labs}\n","\n","# load data\n","train_path = Path(\"final_dataset/normal/train.conll\")\n","val_path   = Path(\"final_dataset/normal/val.conll\")\n","test_path  = Path(\"final_dataset/normal/test.conll\")\n","\n","raw = {\n","    \"train\": read_conll(train_path),\n","    \"validation\": read_conll(val_path),\n","    \"test\": read_conll(test_path),\n","}\n","data = DatasetDict({k: Dataset.from_dict(v) for k, v in raw.items()})\n","\n","#Model name -------------------------------------------------------------\n","model_name = \"Marijke/greberta_hypopt_NER\"\n","tokenizer  = AutoTokenizer.from_pretrained(model_name)\n","#------------------------------------------------------------------------\n","\n","all_labels = sorted({l for s in data[\"train\"][\"ner_tags\"] for l in s})\n","label2id   = {l: i for i, l in enumerate(all_labels)}\n","id2label   = {i: l for l, i in label2id.items()}\n","\n","#tokenise + align labels\n","def tokenise_align(example):\n","    tok = tokenizer(example[\"tokens\"], truncation=True, is_split_into_words=True)\n","    aligned = []\n","    for i, labs in enumerate(example[\"ner_tags\"]):\n","        word_ids = tok.word_ids(batch_index=i)\n","        prev = None\n","        ids  = []\n","        for wid in word_ids:\n","            if wid is None:\n","                ids.append(-100)\n","            elif wid != prev:\n","                ids.append(label2id[labs[wid]])\n","            else:\n","                ids.append(-100)               # sub-word → ignore\n","            prev = wid\n","        aligned.append(ids)\n","    tok[\"labels\"] = aligned\n","    return tok\n","\n","tokenised = data.map(tokenise_align, batched=True,\n","                     remove_columns=data[\"train\"].column_names)\n","\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(all_labels),\n","    id2label=id2label,\n","    label2id=label2id,\n",")\n","\n","collator = DataCollatorForTokenClassification(tokenizer)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":538},"id":"M48lINeotYTu","executionInfo":{"status":"error","timestamp":1763399187221,"user_tz":300,"elapsed":65,"user":{"displayName":"Javier Marsicano","userId":"11865106587474936769"}},"outputId":"f64db561-29b8-415f-a4a8-db5eaff19e42"},"execution_count":6,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'GenerationMixin' from 'transformers.generation' (/usr/local/lib/python3.12/dist-packages/transformers/generation/__init__.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3052312181.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForTokenClassification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataCollatorForTokenClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderDecoderConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m from .configuration_auto import (\n\u001b[1;32m     42\u001b[0m     \u001b[0mCONFIG_MAPPING_NAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'GenerationMixin' from 'transformers.generation' (/usr/local/lib/python3.12/dist-packages/transformers/generation/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import evaluate\n","from seqeval.metrics import classification_report\n","\n","def compute_metrics(p):\n","    preds, labels = p\n","    preds = np.argmax(preds, axis=2)\n","\n","    true_labels = []\n","    pred_labels = []\n","\n","    for prediction, label in zip(preds, labels):\n","        true_seq = [id2label[l] for l in label if l != -100]\n","        pred_seq = [id2label[pred] for pred, l in zip(prediction, label) if l != -100]\n","        if true_seq:  # Only add if not empty\n","            true_labels.append(true_seq)\n","            pred_labels.append(pred_seq)\n","\n","    if not true_labels:\n","        return {\"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0}\n","\n","\n","    metric = evaluate.load(\"seqeval\")\n","    results = metric.compute(predictions=pred_labels, references=true_labels)\n","    print(results)\n","\n","    return {\n","      \"precision\": results[\"overall_precision\"],\n","      \"recall\": results['overall_recall'],\n","      \"f1\": results[\"overall_f1\"]\n","    }\n","\n"],"metadata":{"id":"77nBByjh5sF3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# Hyper-parameters\n","# ------------------------------------------------------------\n","LEARNING_RATE = 3e-5\n","BATCH_SIZE    = 16\n","EPOCHS        = 5\n","WEIGHT_DECAY  = 0.01\n","WARMUP_RATIO  = 0.06\n","SEED          = 123\n","OUTPUT_DIR    = \"./tuned_ner_model\"\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=LEARNING_RATE,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    num_train_epochs=EPOCHS,\n","    weight_decay=WEIGHT_DECAY,\n","    warmup_ratio=WARMUP_RATIO,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    seed=SEED,\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to=[],\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenised[\"train\"],\n","    eval_dataset=tokenised[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","#Train the model\n","print(\"\\nSTARTING TRAINING ...\\n\")\n","trainer.train()\n","\n","#Save the model\n","trainer.save_model(OUTPUT_DIR)\n","tokenizer.save_pretrained(OUTPUT_DIR)\n","print(f\"\\nModel saved to {OUTPUT_DIR}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":498,"referenced_widgets":["84ce2ae968234bb5a0d9607e4f3c9df8","30a6493d641f4440be92bf29a188f815","f7b17de316934570a773e51bb31f4823","945432ac1ec547269baf1b8b048d7004","e5460747cc8a4769ad2871a54658ab1b","d9adee0542264abfa0bfd5ae385e32d4","285e99558f9044c5a511780789ec976f","ff35bfcdcc664b8aa23a3f2ce0248a95","57ea40b53c8b4fb4986f0c022db4af29","c88d314d8f014d529c505d147ec3e082","12e63314a9d44c7186196139ac6241b5"]},"id":"oTOvrHmvzdwG","executionInfo":{"status":"ok","timestamp":1763350153172,"user_tz":480,"elapsed":1147042,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}},"outputId":"8cbbe4bc-6190-4a85-9b51-f09e081ffc01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2236131195.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"stream","name":"stdout","text":["\n","STARTING TRAINING ...\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9590' max='9590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9590/9590 19:01, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.039400</td>\n","      <td>0.099955</td>\n","      <td>0.823198</td>\n","      <td>0.829596</td>\n","      <td>0.826385</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.014500</td>\n","      <td>0.113058</td>\n","      <td>0.823062</td>\n","      <td>0.836472</td>\n","      <td>0.829713</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.009200</td>\n","      <td>0.123023</td>\n","      <td>0.828902</td>\n","      <td>0.834230</td>\n","      <td>0.831558</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.010500</td>\n","      <td>0.140278</td>\n","      <td>0.836154</td>\n","      <td>0.834529</td>\n","      <td>0.835341</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.002700</td>\n","      <td>0.146498</td>\n","      <td>0.831911</td>\n","      <td>0.844843</td>\n","      <td>0.838327</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84ce2ae968234bb5a0d9607e4f3c9df8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'GRP': {'precision': np.float64(0.7902097902097902), 'recall': np.float64(0.8752904725019365), 'f1': np.float64(0.8305769937522969), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.7377543330821401), 'recall': np.float64(0.7278810408921933), 'f1': np.float64(0.7327844311377245), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8634880803011292), 'recall': np.float64(0.8487913172175628), 'f1': np.float64(0.8560766264460753), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.8231978641352714), 'overall_recall': np.float64(0.8295964125560538), 'overall_f1': np.float64(0.826384752829065), 'overall_accuracy': 0.9769274815588265}\n","{'GRP': {'precision': np.float64(0.7739307535641547), 'recall': np.float64(0.8830364058869093), 'f1': np.float64(0.8248914616497829), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.7263389581804842), 'recall': np.float64(0.7360594795539034), 'f1': np.float64(0.7311669128508124), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8745899571032046), 'recall': np.float64(0.8549580661075481), 'f1': np.float64(0.8646625919920169), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.8230622150316222), 'overall_recall': np.float64(0.8364723467862482), 'overall_f1': np.float64(0.8297130995626066), 'overall_accuracy': 0.977399036680252}\n","{'GRP': {'precision': np.float64(0.7971929824561403), 'recall': np.float64(0.8799380325329202), 'f1': np.float64(0.8365243004418262), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.7286027798098025), 'recall': np.float64(0.7405204460966542), 'f1': np.float64(0.7345132743362831), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8751585891905608), 'recall': np.float64(0.8507646768623581), 'f1': np.float64(0.8627892432770481), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.8289024209119263), 'overall_recall': np.float64(0.8342301943198804), 'overall_f1': np.float64(0.8315577739700514), 'overall_accuracy': 0.9775000842062717}\n","{'GRP': {'precision': np.float64(0.7801082543978349), 'recall': np.float64(0.8931061192873742), 'f1': np.float64(0.8327916215240158), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.7781350482315113), 'recall': np.float64(0.7197026022304833), 'f1': np.float64(0.7477790652761684), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8753476611883692), 'recall': np.float64(0.8539713862851505), 'f1': np.float64(0.864527406667499), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.8361539613598922), 'overall_recall': np.float64(0.8345291479820628), 'overall_f1': np.float64(0.8353407645694622), 'overall_accuracy': 0.977814454287222}\n","{'GRP': {'precision': np.float64(0.792911744266852), 'recall': np.float64(0.8838109992254066), 'f1': np.float64(0.8358974358974358), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.7687400318979266), 'recall': np.float64(0.7167286245353159), 'f1': np.float64(0.7418237783762985), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8649109973177274), 'recall': np.float64(0.8749383325111002), 'f1': np.float64(0.869895769466585), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.8319105092728878), 'overall_recall': np.float64(0.8448430493273542), 'overall_f1': np.float64(0.8383269059626224), 'overall_accuracy': 0.9781512793739544}\n","\n","Model saved to ./tuned_ner_model\n"]}]},{"cell_type":"code","source":["#Quick test\n","from transformers import pipeline\n","import unicodedata\n","\n","ner = pipeline(\"ner\", model=OUTPUT_DIR, tokenizer=OUTPUT_DIR,\n","               aggregation_strategy=\"simple\")\n","\n","txt = unicodedata.normalize(\"NFC\", \"\"\"\n","  ᾿Ανέστη δὲ βασιλεὺς ἕτερος ἐπ᾿ Αἴγυπτον, ὃς οὐκ ᾔδει τὸν ᾿Ιωσήφ.\n","  εἶπε δὲ τῷ ἔθνει αὐτοῦ· ἰδοὺ τὸ γένος τῶν υἱῶν ᾿Ισραὴλ μέγα πλῆθος καὶ ἰσχύει ὑπὲρ ἡμᾶς·\n","  δεῦτε οὖν κατασοφισώμεθα αὐτούς, μή ποτε πληθυνθῇ, καὶ ἡνίκα ἂν συμβῇ ἡμῖν πόλεμος,\n","  προστεθήσονται καὶ οὗτοι πρὸς τοὺς ὑπεναντίους καὶ ἐκπολεμήσαντες ἡμᾶς ἐξελεύσονται ἐκ τῆς γῆς.\n","  καὶ ἐπέστησεν αὐτοῖς ἐπιστάτας τῶν ἔργων, ἵνα κακώσωσιν αὐτοὺς ἐν τοῖς ἔργοις· καὶ Ισραήλᾠκοδόμησαν πόλεις ὀχυρὰς τῷ Φαραώ, τήν τε Πειθὼ καὶ Ῥαμεσσῆ καὶ ῎Ων, ἥ ἐστιν ῾Ηλιούπολις.\n","  καθότι δὲ αὐτοὺς ἐταπείνουν, τοσούτῳ πλείους ἐγίγνοντο, καὶ ἴσχυον σφόδρα σφόδρα· καὶ ἐβδελύσσοντο οἱ Αἰγύπτιοι ἀπὸ τῶν υἱῶν ᾿.\n","  καὶ κατεδυνάστευον οἱ Αἰγύπτιοι τοὺς υἱοὺς ᾿Ισραὴλ βίᾳ καὶ κατωδύνων αὐτῶν τὴν ζωὴν ἐν τοῖς ἔργοις τοῖς σκληροῖς, τῷ πηλῷ καὶ τῇ πλινθείᾳ καὶ πᾶσι τοῖς ἔργοις τοῖς ἐν τοῖς πεδίοις, κατὰ πάντα τὰ ἔργα, ὧν κατεδουλοῦντο αὐτοὺς μετὰ βίας.\n","\"\"\")\n","\n","merged_results = []\n","\n","for r in ner(txt):\n","    if r['word'].startswith(\"##\"):\n","        merged_results[-1]['word'] += r['word'][2:]  # remove ## and join the subwords together instead of splitting it\n","        merged_results[-1]['score'] = max(merged_results[-1]['score'], r['score'])\n","    else:\n","        merged_results.append(r)\n","\n","for r in merged_results:\n","    print(f\"{r['word']:<20} → {r['entity_group']:<6} ({r['score']:.3f})\")\n"],"metadata":{"id":"expUuoIklEdc","executionInfo":{"status":"ok","timestamp":1763350153446,"user_tz":480,"elapsed":271,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1a5b6e6-90ce-43fe-9564-0a8f7bf0c497"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["αιγυπτον             → LOC    (0.997)\n","φαραω                → PERS   (0.999)\n","ραμεσση              → LOC    (0.960)\n","αιγυπτιοι            → GRP    (1.000)\n","αιγυπτιοι            → GRP    (1.000)\n"]}]},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# Hyper-parameters\n","# ------------------------------------------------------------\n","LEARNING_RATE = 3e-5\n","BATCH_SIZE    = 32\n","EPOCHS        = 5\n","WEIGHT_DECAY  = 0.01\n","WARMUP_RATIO  = 1.0\n","SEED          = 123\n","OUTPUT_DIR    = f\"./tuned_ner_model_lr{LEARNING_RATE}_bs{BATCH_SIZE}_ep{EPOCHS}\"\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=LEARNING_RATE,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    num_train_epochs=EPOCHS,\n","    weight_decay=WEIGHT_DECAY,\n","    warmup_ratio=WARMUP_RATIO,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    seed=SEED,\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to=[],\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenised[\"train\"],\n","    eval_dataset=tokenised[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431},"id":"kyHhVrMr_yxg","executionInfo":{"status":"ok","timestamp":1763351300713,"user_tz":480,"elapsed":1147254,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}},"outputId":"ecfadee5-617f-4856-9938-30d3d06ff27f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2947403601.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4795' max='4795' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4795/4795 19:06, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.003200</td>\n","      <td>0.153893</td>\n","      <td>0.831669</td>\n","      <td>0.846338</td>\n","      <td>0.838939</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.004300</td>\n","      <td>0.156487</td>\n","      <td>0.825432</td>\n","      <td>0.843199</td>\n","      <td>0.834221</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.008700</td>\n","      <td>0.161607</td>\n","      <td>0.836168</td>\n","      <td>0.837668</td>\n","      <td>0.836918</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.009400</td>\n","      <td>0.156468</td>\n","      <td>0.830458</td>\n","      <td>0.834679</td>\n","      <td>0.832563</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.002600</td>\n","      <td>0.167400</td>\n","      <td>0.809701</td>\n","      <td>0.845889</td>\n","      <td>0.827400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'GRP': {'precision': np.float64(0.7855684138869979), 'recall': np.float64(0.8938807126258714), 'f1': np.float64(0.836231884057971), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.7770545158665582), 'recall': np.float64(0.7100371747211895), 'f1': np.float64(0.742035742035742), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8644768856447689), 'recall': np.float64(0.8764183522446966), 'f1': np.float64(0.8704066634002938), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.831668625146886), 'overall_recall': np.float64(0.8463378176382661), 'overall_f1': np.float64(0.8389391020891984), 'overall_accuracy': 0.9781849618826277}\n","{'GRP': {'precision': np.float64(0.7809330628803245), 'recall': np.float64(0.8946553059643687), 'f1': np.float64(0.8339350180505415), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.727866473149492), 'recall': np.float64(0.745724907063197), 'f1': np.float64(0.7366874770473741), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.87578576816696), 'recall': np.float64(0.8591514553527381), 'f1': np.float64(0.8673888681359732), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.8254316652033948), 'overall_recall': np.float64(0.8431988041853513), 'overall_f1': np.float64(0.8342206447796511), 'overall_accuracy': 0.9780165493392614}\n","{'GRP': {'precision': np.float64(0.8189845474613686), 'recall': np.float64(0.8621223857474826), 'f1': np.float64(0.84), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.778321108394458), 'recall': np.float64(0.7100371747211895), 'f1': np.float64(0.7426127527216174), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.859086491739553), 'recall': np.float64(0.8722249629995067), 'f1': np.float64(0.8656058751529989), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.8361683079677709), 'overall_recall': np.float64(0.8376681614349776), 'overall_f1': np.float64(0.8369175627240144), 'overall_accuracy': 0.9778593642987863}\n","{'GRP': {'precision': np.float64(0.7731322823851954), 'recall': np.float64(0.8737412858249419), 'f1': np.float64(0.8203636363636364), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.7580015612802498), 'recall': np.float64(0.7219330855018588), 'f1': np.float64(0.7395277989337395), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8747489959839357), 'recall': np.float64(0.8596447952639369), 'f1': np.float64(0.8671311271460563), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.8304580606781677), 'overall_recall': np.float64(0.8346786248131539), 'overall_f1': np.float64(0.8325629938869837), 'overall_accuracy': 0.9773541266686876}\n","{'GRP': {'precision': np.float64(0.73579013116802), 'recall': np.float64(0.9124709527498064), 'f1': np.float64(0.814661134163209), 'number': np.int64(1291)}, 'LOC': {'precision': np.float64(0.760357432981316), 'recall': np.float64(0.695910780669145), 'f1': np.float64(0.7267080745341614), 'number': np.int64(1345)}, 'PERS': {'precision': np.float64(0.8527784459947078), 'recall': np.float64(0.8744449925999014), 'f1': np.float64(0.8634758251126539), 'number': np.int64(4054)}, 'overall_precision': np.float64(0.809700958649306), 'overall_recall': np.float64(0.8458893871449925), 'overall_f1': np.float64(0.8273996637181079), 'overall_accuracy': 0.9767702965183513}\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4795, training_loss=0.00430331057067708, metrics={'train_runtime': 1146.6349, 'train_samples_per_second': 133.809, 'train_steps_per_second': 4.182, 'total_flos': 7583996353035300.0, 'train_loss': 0.00430331057067708, 'epoch': 5.0})"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Zero-shot transfer:  Due to its nature that the ground\n","truth label exists at word level, supervised training of NER models often requires large amount\n","of human annotation efforts. In real-world use\n","cases where one needs to build multi-lingual models, the required human labor scales at least linearly with number of languages, or even worse\n","for low resource languages. Li, B., He, Y., & Xu, W. (2021). Cross-Lingual Named Entity Recognition Using Parallel Corpus: A New Approach Using XLM-RoBERTa Alignment. arXiv\n","https://arxiv.org/pdf/2101.11112\n","\n"],"metadata":{"id":"8k9KQBAk0rhh"}},{"cell_type":"code","source":["# https://huggingface.co/datasets/hmcgovern/original-language-bibles-greek\n","import pandas as pd\n","\n","dataset_hf_path = '/content/drive/MyDrive/Deep Learning Group Project/train-00000-of-00001.parquet'\n","dataset_hf = pd.read_parquet(dataset_hf_path)\n","dataset_hf.head(10)\n","len(dataset_hf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G-WPgchqqijy","executionInfo":{"status":"ok","timestamp":1763351317085,"user_tz":480,"elapsed":16369,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}},"outputId":"749eb30b-19c4-4ac0-adac-326f7baf567e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["142097"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import os\n","import torch\n","import joblib\n","import pandas as pd\n","from tqdm.auto import tqdm\n","from transformers import pipeline\n","from datasets import Dataset\n","\n","# ----- SETTINGS -----\n","CACHE_FILE     = \"/content/drive/MyDrive/Deep Learning Group Project/ner_labels_wordlevel.pkl.gz\"\n","CSV_OUT_FILE   = \"/content/drive/MyDrive/Deep Learning Group Project/ner_labels.csv\"\n","WORDS_PER_BATCH = 64          # how many *words* to join into one fake sentence since the dataset is on word\n","HF_BATCH_SIZE   = 64          # pipeline internal batch size (sentences)\n","# -------------------------\n","\n","device = 0 if torch.cuda.is_available() else -1\n","print(f\"NER device: {'GPU' if device == 0 else 'CPU'}\")\n","\n","ner_model = pipeline(\n","    \"ner\",\n","    model=\"dslim/bert-base-NER\",\n","    aggregation_strategy=\"simple\",\n","    device=device,\n","    batch_size=HF_BATCH_SIZE,\n",")\n","\n","def ner_on_word_batch(word_list):\n","    if not word_list:\n","        return []\n","\n","    fake_sentence = \" \".join(word_list)\n","    entities = ner_model(fake_sentence)\n","    labels = [\"O\"] * len(word_list)\n","\n","    char_pos = 0\n","    for ent in entities:\n","        ent_start = ent[\"start\"]\n","        ent_label = ent[\"entity_group\"]\n","\n","        word_idx = 0\n","        current_pos = 0\n","        while word_idx < len(word_list):\n","            word_len = len(word_list[word_idx])\n","            if current_pos <= ent_start < current_pos + word_len:\n","                labels[word_idx] = ent_label\n","                break\n","            current_pos += word_len + 1\n","            word_idx += 1\n","\n","    return labels\n","\n","if os.path.exists(CACHE_FILE):\n","    print(f\"Loading cached NER labels from:\\n    {CACHE_FILE}\")\n","    final_labels = joblib.load(CACHE_FILE)\n","else:\n","    print(f\"Cache missing → running batched NER on {len(dataset_hf)} words...\")\n","    final_labels = []\n","\n","    words = dataset_hf[\"translation\"].tolist()\n","\n","    for i in tqdm(range(0, len(words), WORDS_PER_BATCH),\n","                  desc=\"NER word batches\",\n","                  total=(len(words) + WORDS_PER_BATCH - 1) // WORDS_PER_BATCH):\n","\n","        batch_words = words[i:i + WORDS_PER_BATCH]\n","        batch_labels = ner_on_word_batch(batch_words)\n","        final_labels.extend(batch_labels)\n","\n","\n","    os.makedirs(os.path.dirname(CACHE_FILE), exist_ok=True)\n","    print(f\"Saving {len(final_labels)} labels → {CACHE_FILE}\")\n","    joblib.dump(final_labels, CACHE_FILE, compress=(\"gzip\", 3))\n","\n","dataset_hf = dataset_hf.assign(ner_label=final_labels)\n","\n","os.makedirs(os.path.dirname(CSV_OUT_FILE), exist_ok=True)\n","dataset_hf[[\"text\", \"translation\", \"ner_label\"]].to_csv(CSV_OUT_FILE, index=False)\n","print(f\"CSV saved: {CSV_OUT_FILE}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":372,"referenced_widgets":["29458f69f2af4390bf4062aa48b5f432","eb2d74a3054e4495acf7d82f16569e63","a2179aba77564755a04a81e53043f4af","294cf2daa7114d5d90f2d25d5582af2c","519d12157573471dab2b4e52bdff0457","2e26ab1a6d6c4847ab0afdb121abedfb","ec4dd203fa504684811eab72e3657731","d2c7a27267ef465ab9df3e387dc35e7c","276df0fde8224ecbafd5c7a895862fd5","a0e2e75984e94a4bafb655ffc063792e","b26e25fbdb9a42e7b88501026808fda9","081276e05a114cbab065894a52874a81","b44891e471ec4cba9f9680329f90ef19","4a06f823d61f42ee8ec6ed7370ea327f","3bcc208ad33c481f9363952cd8e524de","468e11e3d8924ed6a8559a717c561c28","8c3593eb608b47c09ad13a9c54f910e5","04bec223570647e181fee9dc44f4ab92","ba3199b9a6aa4c7c8dda4ce83ceb4d63","ceed661f97f74d96a73407370fdf3493","75417d7e195045129dc96c7f706cd139","3b892715505b42099005a4786ebb13b1","ae53fbb4dce84c0199e7aa323406a0ae","42756ae0205649adbdd90c3eb3ec5e4c","82c7d8836afa4d39abed176268ee05d9","dbba4bfe9f5f4347872f3f22ed14080a","ee703f78c153450ca46c72fbc949e35e","5572a8435ddd40cfbaf06178314bf083","48a2f2fc037a4f2c9c708eddb3ef4e5d","01b5b70e6aa54ea8be2df0a2128df3a7","ad84f90562a047cfac9b4ecd69699651","5613e3d6eb4648a7af840dd676f4e987","a0140e3226484c989c7a1c8cc8abcd91","9f1b17157c37499781615fc9f11e2dd6","6d54061c959a4cdb8b143b57736bf6f3","0f6b56436bbd417290289223e1b2f473","67f4170c0133425e98c61d9f4904cb63","f2f25c89861840f39cd8e8e864e892d5","e1a17ba7e93245a9b0ccc7be05d4a510","4638323a83bd4c7dbe3816eee507fb80","dcac406c115e4b278f61694adf6a8b4b","b231be8fffea41048477e619fe6d7e5b","c830a483c2be4e59b0699c0ac753eec9","bd1da9a661fc43ab83df00041141b936","402bb9d1315a4875b80576a9b9d56eaf","1d452f19141a4d61a3225435cff91192","88389f4a4e614c849677160f42136249","f6ce3ad89d2c4ac98d55247d4efe39e8","ce7fb0bfeefe479c9608930b72853d44","6dc01d7a0357497592b684df8d90bd9a","daa802996bd1471d850779dc99096cb6","eda506f61d744ca9bf665652a7fb2fab","2d2c3d5a380e4d55948f539c7c688abb","45c51ae7e6754fb098880117f781435d","dd87f24abde44c3e95002339db09e1df","6342b119fc9d4820b1a895a71f8c44db","7c8baee0ad51412d8b358bc6b61a63f7","bd05467771564315837d3a6b35a299df","329e056267b94340ac3f253333a8b7ce","9e4a02322c0847bf9f3c53558057a375","2e83788175aa46f4a9e3f10ceaaa7d69","89aa1234c0834ccab2e8274bb2f992d8","688f805c26ef41dbbfa57f2c340670a5","e8460785098548f7af2713ca3bd9d50e","e60505abda5f4bd2b307c36edb71df59","205dc5f8fc67464587f0ef45e0a90ee1"]},"id":"ppFzhNtszAWH","executionInfo":{"status":"ok","timestamp":1763351321367,"user_tz":480,"elapsed":4280,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}},"outputId":"5618e3c2-953d-4147-b368-e59736b068fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NER device: GPU\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29458f69f2af4390bf4062aa48b5f432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"081276e05a114cbab065894a52874a81"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae53fbb4dce84c0199e7aa323406a0ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f1b17157c37499781615fc9f11e2dd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"402bb9d1315a4875b80576a9b9d56eaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6342b119fc9d4820b1a895a71f8c44db"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Loading cached NER labels from:\n","    /content/drive/MyDrive/Deep Learning Group Project/ner_labels_wordlevel.pkl.gz\n","CSV saved: /content/drive/MyDrive/Deep Learning Group Project/ner_labels.csv\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"zXs679rH37zo"}},{"cell_type":"code","source":["### 1. Need to convert the ner label to BIO format first\n","### 2. Join the new dataset to the existing trainingdata\n","\n","\n","from datasets import concatenate_datasets\n","import os\n","\n","print(f\"Original train rows: {len(data['train'])}\")\n","print(f\"Original train features: {data['train'].features}\")\n","\n","from datasets import Features, Value, Sequence\n","\n","new_dataset = Dataset.from_dict({\n","    \"tokens\": dataset_hf[\"text\"].tolist(),\n","    \"ner_tags\": dataset_hf[\"ner_label\"].tolist(),\n","})\n","print(new_dataset)\n","\n","expected_features = Features({\n","    \"tokens\": Sequence(Value(\"string\")),\n","    \"ner_tags\": Value(\"string\"),\n","})\n","\n","print(f\"Adding {len(new_dataset)} NER examples to train...\")\n","data[\"train\"] = concatenate_datasets([data[\"train\"], new_dataset])\n","\n","print(f\"New train size: {len(data['train'])} rows\")\n","\n","print(\"Tokenizing full train split...\")\n","tokenised_train = data[\"train\"].map(\n","    tokenise_align,\n","    batched=True,\n","    num_proc=os.cpu_count(),\n","    batch_size=2000,\n","    remove_columns=data[\"train\"].column_names,  # keep only tokenizer outputs\n",")\n","\n","data[\"train\"] = tokenised_train\n","\n","\n","print(f\"Tokenization complete!\")\n","print(f\"Final train rows: {len(data['train'])}\")\n","print(f\"Final columns: {data['train'].column_names}\")\n","print(f\"Example: {data['train'][0].keys()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZDRFZ8u_y6m","executionInfo":{"status":"error","timestamp":1763351321462,"user_tz":480,"elapsed":80,"user":{"displayName":"Sarah Batara","userId":"04777559678768349971"}},"outputId":"a488c7b2-bc34-4926-b066-694ac68ea78c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original train rows: 30686\n","Original train features: {'tokens': List(Value('string')), 'ner_tags': List(Value('string'))}\n","Dataset({\n","    features: ['tokens', 'ner_tags'],\n","    num_rows: 142097\n","})\n","Adding 142097 NER examples to train...\n"]},{"output_type":"error","ename":"ValueError","evalue":"The features can't be aligned because the key tokens of features {'tokens': Value('string'), 'ner_tags': Value('string')} has unexpected type - Value('string') (expected either List(Value('string')) or Value(\"null\").","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3704149241.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Adding {len(new_dataset)} NER examples to train...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"New train size: {len(data['train'])} rows\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/combine.py\u001b[0m in \u001b[0;36mconcatenate_datasets\u001b[0;34m(dsets, info, split, axis)\u001b[0m\n\u001b[1;32m    211\u001b[0m             )\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_concatenate_map_style_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_concatenate_iterable_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_concatenate_map_style_datasets\u001b[0;34m(dsets, info, split, axis)\u001b[0m\n\u001b[1;32m   6404\u001b[0m     \u001b[0;31m# Perform checks (and a potential cast if axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6406\u001b[0;31m         \u001b[0m_check_if_features_can_be_aligned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m_check_if_features_can_be_aligned\u001b[0;34m(features_list)\u001b[0m\n\u001b[1;32m   2299\u001b[0m                 \u001b[0m_check_if_features_can_be_aligned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname2feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2300\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"null\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname2feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2301\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2302\u001b[0m                     \u001b[0;34mf'The features can\\'t be aligned because the key {k} of features {features} has unexpected type - {v} (expected either {name2feature[k]} or Value(\"null\").'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2303\u001b[0m                 )\n","\u001b[0;31mValueError\u001b[0m: The features can't be aligned because the key tokens of features {'tokens': Value('string'), 'ner_tags': Value('string')} has unexpected type - Value('string') (expected either List(Value('string')) or Value(\"null\")."]}]},{"cell_type":"code","source":["#and then save it for future training\n","def save_hf_dataset_to_conll(dataset, output_file):\n","\n","    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n","        for example in dataset:\n","            tokens = example[\"tokens\"]\n","            labels = example[\"ner_tags\"]\n","\n","            for token, label in zip(tokens, labels):\n","                f.write(f\"{token}\\t{label}\\n\")  # tab-separated\n","            f.write(\"\\n\")  # sentence boundary\n","\n","# Example: convert train split\n","save_hf_dataset_to_conll(dataset_hf[\"train\"], \"train_from_hf.conll\")\n","save_hf_dataset_to_conll(dataset_hf[\"test\"], \"test_from_hf.conll\")\n","\n"],"metadata":{"id":"3gKX7f0m_y9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8Xyv3sFM_zAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# Hyper-parameters\n","# ------------------------------------------------------------\n","LEARNING_RATE = 3e-5\n","BATCH_SIZE    = 32\n","EPOCHS        = 10\n","WEIGHT_DECAY  = 0.001\n","WARMUP_RATIO  = 0.6\n","SEED          = 123\n","OUTPUT_DIR    = f\"./tuned_ner_model_lr{LEARNING_RATE}_bs{BATCH_SIZE}_ep{EPOCHS}\"\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=LEARNING_RATE,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    num_train_epochs=EPOCHS,\n","    weight_decay=WEIGHT_DECAY,\n","    warmup_ratio=WARMUP_RATIO,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    seed=SEED,\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to=[],\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenised[\"train\"],\n","    eval_dataset=tokenised[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"metadata":{"id":"M73F4XjH_zDT"},"execution_count":null,"outputs":[]}]}
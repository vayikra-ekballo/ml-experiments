{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPAijqP6ZjJXI9AI9IgRl5H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6e2ec1bf619a470487b6bfce3967c85e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a59899cd6ddd4aedb4391e5f8498e49c","IPY_MODEL_42d763f08027471096efd5e2e1d0e8e0","IPY_MODEL_64fb712b875a42cb936edf9e03592c08"],"layout":"IPY_MODEL_c7ea2945bfef46b4a167c040b31ad2a6"}},"a59899cd6ddd4aedb4391e5f8498e49c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c10485db3d046c2afb6519b675eea1a","placeholder":"​","style":"IPY_MODEL_04965eea4e524da0af5cc30231188aa1","value":"tokenizer_config.json: "}},"42d763f08027471096efd5e2e1d0e8e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e089997473841d8b8c6274f4c57c85e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5740ec8cd644585b0e4c3b76ae73c62","value":1}},"64fb712b875a42cb936edf9e03592c08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8041789b24ef47fc9d60b45142a724c5","placeholder":"​","style":"IPY_MODEL_46bffe143a4a4a408bdb892c8d4997a4","value":" 1.37k/? [00:00&lt;00:00, 149kB/s]"}},"c7ea2945bfef46b4a167c040b31ad2a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c10485db3d046c2afb6519b675eea1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04965eea4e524da0af5cc30231188aa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e089997473841d8b8c6274f4c57c85e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f5740ec8cd644585b0e4c3b76ae73c62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8041789b24ef47fc9d60b45142a724c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46bffe143a4a4a408bdb892c8d4997a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c147e5ae9096422dbe48d468569be2ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8a4d03189d14485b55c7fe5c232be89","IPY_MODEL_712be79adcca40eea96683fc60181f6a","IPY_MODEL_1ba4d84839ff42f1b70b388b6c7565d8"],"layout":"IPY_MODEL_8c3e3d5132ac4ab0af8679c697bed8e8"}},"c8a4d03189d14485b55c7fe5c232be89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cfe1b91ed7c43c7912b898f724a6099","placeholder":"​","style":"IPY_MODEL_807c77140df6431ba0d64604f2040ce0","value":"vocab.json: "}},"712be79adcca40eea96683fc60181f6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a537d9e232144c7bb5695ed93f9c2418","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea13382dbde349c3a37ea1fd5fad6da9","value":1}},"1ba4d84839ff42f1b70b388b6c7565d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f08ccfccf6e849479463f542b0fe9ec5","placeholder":"​","style":"IPY_MODEL_0aadc73a51584b82a57f0522175e039b","value":" 1.69M/? [00:00&lt;00:00, 77.2MB/s]"}},"8c3e3d5132ac4ab0af8679c697bed8e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cfe1b91ed7c43c7912b898f724a6099":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"807c77140df6431ba0d64604f2040ce0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a537d9e232144c7bb5695ed93f9c2418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ea13382dbde349c3a37ea1fd5fad6da9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f08ccfccf6e849479463f542b0fe9ec5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aadc73a51584b82a57f0522175e039b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf3226a49c5b4c0e80e631040a506dce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a276a2c94e304fe0ae2ad4a0a485c2cc","IPY_MODEL_e14aceb14a6442338fbc7ee66a905491","IPY_MODEL_dc2abb33d6bd416baace501d1c383807"],"layout":"IPY_MODEL_542bf25ef0a944159c01fbff7dafa40f"}},"a276a2c94e304fe0ae2ad4a0a485c2cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d79dd9477722494a8ae08e7353a1face","placeholder":"​","style":"IPY_MODEL_59931687801a4be8926651340b56f787","value":"merges.txt: "}},"e14aceb14a6442338fbc7ee66a905491":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebaa75589130470fbe932da4352ad47e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1979d24963824e6f9dcc6088d3aa8412","value":1}},"dc2abb33d6bd416baace501d1c383807":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae78fa8f2749407a82a78e0ffe4302aa","placeholder":"​","style":"IPY_MODEL_7384ed02eb8c42e2aac2d5f03d0af411","value":" 1.34M/? [00:00&lt;00:00, 75.5MB/s]"}},"542bf25ef0a944159c01fbff7dafa40f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d79dd9477722494a8ae08e7353a1face":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59931687801a4be8926651340b56f787":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebaa75589130470fbe932da4352ad47e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1979d24963824e6f9dcc6088d3aa8412":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae78fa8f2749407a82a78e0ffe4302aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7384ed02eb8c42e2aac2d5f03d0af411":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90ecc93249614d92ab1fb56b2acc7664":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1d7115bba5f452cb149ccfffbeef6db","IPY_MODEL_1106c4aeccb148f192d8d5420bd6a669","IPY_MODEL_0d4265670d29490d979b54ded50c3c3c"],"layout":"IPY_MODEL_4184764c38f9461f9fd09d26650e4e4e"}},"d1d7115bba5f452cb149ccfffbeef6db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_642b7760027546468fb75cedfdfed316","placeholder":"​","style":"IPY_MODEL_98c87fe9196d4c61a782aaad1eab1883","value":"tokenizer.json: "}},"1106c4aeccb148f192d8d5420bd6a669":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3514464f12a94fdea873fee293f1d983","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85d90feabb2545bbb94ce1570ec52311","value":1}},"0d4265670d29490d979b54ded50c3c3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f62ca3e40a484d1ab743a696ab701e60","placeholder":"​","style":"IPY_MODEL_553a287a08464079bb944467c9d532fa","value":" 3.91M/? [00:00&lt;00:00, 105MB/s]"}},"4184764c38f9461f9fd09d26650e4e4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"642b7760027546468fb75cedfdfed316":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98c87fe9196d4c61a782aaad1eab1883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3514464f12a94fdea873fee293f1d983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"85d90feabb2545bbb94ce1570ec52311":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f62ca3e40a484d1ab743a696ab701e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"553a287a08464079bb944467c9d532fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dfd451ff56140b794eaeb31c46b1627":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b6c7278dc264cd0add7acab42350a03","IPY_MODEL_4041a15485714e7a9eb565b72d87a8c5","IPY_MODEL_bbb3e8804a324b7ab56363af25c2118c"],"layout":"IPY_MODEL_c4e11f691ecb4052a0116e601562c8c6"}},"1b6c7278dc264cd0add7acab42350a03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dd4788ab80b4a42934450794538d979","placeholder":"​","style":"IPY_MODEL_3433ed00e8804dfe8a567bc5aeb0f802","value":"special_tokens_map.json: 100%"}},"4041a15485714e7a9eb565b72d87a8c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc75e721371c49adbe6fe89c51640445","max":957,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87e3b90c2b3748749339c19e0e98f049","value":957}},"bbb3e8804a324b7ab56363af25c2118c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba1e0e927da94a57ae75bf2a3acf1d3a","placeholder":"​","style":"IPY_MODEL_813c2f7c28a74e6ca772c1a8acf77954","value":" 957/957 [00:00&lt;00:00, 90.4kB/s]"}},"c4e11f691ecb4052a0116e601562c8c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dd4788ab80b4a42934450794538d979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3433ed00e8804dfe8a567bc5aeb0f802":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc75e721371c49adbe6fe89c51640445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87e3b90c2b3748749339c19e0e98f049":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba1e0e927da94a57ae75bf2a3acf1d3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"813c2f7c28a74e6ca772c1a8acf77954":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"394ae7209e594146a4f88fdd846be526":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca75ab7864fe4276813b53566e3da7ff","IPY_MODEL_121d386328d44925b713e16e71805a26","IPY_MODEL_3b95ad29ada54ad2b0cb9c533609be47"],"layout":"IPY_MODEL_0ff3d3fb55bd404081a98d8112b4a0d9"}},"ca75ab7864fe4276813b53566e3da7ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4c55ccaa7014af287741367b83dd2ff","placeholder":"​","style":"IPY_MODEL_b976cb7b269145e28e1e340ac02e12ad","value":"config.json: 100%"}},"121d386328d44925b713e16e71805a26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d233648bd5ea49b6badec5c87f5f64fe","max":675,"min":0,"orientation":"horizontal","style":"IPY_MODEL_425e7e182adb4160b51e30237f63f782","value":675}},"3b95ad29ada54ad2b0cb9c533609be47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05d4f619c4424da58b52a2307b85394b","placeholder":"​","style":"IPY_MODEL_feb0459de9bc49abaa4743b18ff0ca5a","value":" 675/675 [00:00&lt;00:00, 98.5kB/s]"}},"0ff3d3fb55bd404081a98d8112b4a0d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4c55ccaa7014af287741367b83dd2ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b976cb7b269145e28e1e340ac02e12ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d233648bd5ea49b6badec5c87f5f64fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"425e7e182adb4160b51e30237f63f782":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05d4f619c4424da58b52a2307b85394b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feb0459de9bc49abaa4743b18ff0ca5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65a731e81315400d85e6899244cd74b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a54caddc2e6843188968f3d0b6c0d595","IPY_MODEL_853b1f5b98f144aa999301f575d906d6","IPY_MODEL_7062adc0d4304ede8726e7542785723a"],"layout":"IPY_MODEL_a1ada5cebc2b4767bb2317905ed6581f"}},"a54caddc2e6843188968f3d0b6c0d595":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21378c829dea4e52b3b311c067266c14","placeholder":"​","style":"IPY_MODEL_77c22670f00f4abd9f233b5a060c9d23","value":"model.safetensors: 100%"}},"853b1f5b98f144aa999301f575d906d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc1fa0e6f6bc4384b6d4f2470c516043","max":504155016,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82db7ba30e344bc897ef55d558d07ae8","value":504155016}},"7062adc0d4304ede8726e7542785723a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79baf8dcda9c412b9a59c0eb98eed52a","placeholder":"​","style":"IPY_MODEL_f87f0e117f4d413eb48e56e8a73926fc","value":" 504M/504M [00:08&lt;00:00, 127MB/s]"}},"a1ada5cebc2b4767bb2317905ed6581f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21378c829dea4e52b3b311c067266c14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77c22670f00f4abd9f233b5a060c9d23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc1fa0e6f6bc4384b6d4f2470c516043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82db7ba30e344bc897ef55d558d07ae8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79baf8dcda9c412b9a59c0eb98eed52a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f87f0e117f4d413eb48e56e8a73926fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08fd142b5817460d9860daf845f72e51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae6fcbb7efcf40fead5a8e7057855f01","IPY_MODEL_fce7f385cfac49ab85cd1c742a503cec","IPY_MODEL_191136443976415cb6459371b884e0ae"],"layout":"IPY_MODEL_536fcf612b744f2fa87eb187c7824533"}},"ae6fcbb7efcf40fead5a8e7057855f01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_963172884d294346b812f5debaa1368c","placeholder":"​","style":"IPY_MODEL_bd54b7ac5b7240bcba797f3e926e6637","value":"Map: 100%"}},"fce7f385cfac49ab85cd1c742a503cec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a19b8b030c524e578a5510d13cce30e5","max":7198,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa118409bd684688b095a33dbe2dda4f","value":7198}},"191136443976415cb6459371b884e0ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0958582961a4f64b2bd0da7915cbfb3","placeholder":"​","style":"IPY_MODEL_4ce69e0452ce42fdb001a215ba16e12a","value":" 7198/7198 [00:00&lt;00:00, 10356.16 examples/s]"}},"536fcf612b744f2fa87eb187c7824533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"963172884d294346b812f5debaa1368c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd54b7ac5b7240bcba797f3e926e6637":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a19b8b030c524e578a5510d13cce30e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa118409bd684688b095a33dbe2dda4f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0958582961a4f64b2bd0da7915cbfb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ce69e0452ce42fdb001a215ba16e12a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d01ee2e63170474493de932c2acc3b39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d68210cf953740d5b6c6f628a18cdddf","IPY_MODEL_07a073c138af45938659fb7096bd013f","IPY_MODEL_5f3b3887ae7a43a6bef2767601518dc8"],"layout":"IPY_MODEL_58eb0faa060e47869097c7f75ebd7d64"}},"d68210cf953740d5b6c6f628a18cdddf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd056bc055864559819ff8ccf666fe35","placeholder":"​","style":"IPY_MODEL_8007f2c4211f41099e49d0cf08366afc","value":"Map: 100%"}},"07a073c138af45938659fb7096bd013f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed2b1085254f40ea8f80547a8fb0f834","max":284,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e705c6445b24090972d6a7b1e128013","value":284}},"5f3b3887ae7a43a6bef2767601518dc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb4e02c445344ecebe4dd7610720aa11","placeholder":"​","style":"IPY_MODEL_a3411c1e90fe4ee980e69c4bf7385370","value":" 284/284 [00:00&lt;00:00, 7111.24 examples/s]"}},"58eb0faa060e47869097c7f75ebd7d64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd056bc055864559819ff8ccf666fe35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8007f2c4211f41099e49d0cf08366afc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed2b1085254f40ea8f80547a8fb0f834":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e705c6445b24090972d6a7b1e128013":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb4e02c445344ecebe4dd7610720aa11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3411c1e90fe4ee980e69c4bf7385370":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6acebfd5832745dea2e219e71c2fd896":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb14f7ae79b54257bfe6ec6c6357fc5b","IPY_MODEL_7fb2dfc6ec1f45a98b9113834d1e87ba","IPY_MODEL_86a22728b25f4f659f3d40e7e5906d2e"],"layout":"IPY_MODEL_a4f985ee2f0d4791a63360532cdbf52c"}},"fb14f7ae79b54257bfe6ec6c6357fc5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_860f9dc1a66544bcb56944f477397bf1","placeholder":"​","style":"IPY_MODEL_2ad0fc1cc1844dfaa874efbf09037bba","value":"Map: 100%"}},"7fb2dfc6ec1f45a98b9113834d1e87ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_abe1582e08aa46ee997a065f82d60b7f","max":443,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa95a7a19d094b16b71b3714c5265b76","value":443}},"86a22728b25f4f659f3d40e7e5906d2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fdf241be3e842b59109ae7a21035e93","placeholder":"​","style":"IPY_MODEL_a3be8b0bfa58422c93db16f9b537053b","value":" 443/443 [00:00&lt;00:00, 6743.08 examples/s]"}},"a4f985ee2f0d4791a63360532cdbf52c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"860f9dc1a66544bcb56944f477397bf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ad0fc1cc1844dfaa874efbf09037bba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abe1582e08aa46ee997a065f82d60b7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa95a7a19d094b16b71b3714c5265b76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fdf241be3e842b59109ae7a21035e93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3be8b0bfa58422c93db16f9b537053b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"aEajA4CXtCbB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TeJ6BSHpsjcz","executionInfo":{"status":"ok","timestamp":1763415799259,"user_tz":300,"elapsed":84938,"user":{"displayName":"Arjun G. Menon","userId":"13198646079844385927"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f18354c-2196-4f59-f448-608b1d9ae487"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import json\n","import argparse\n","from pathlib import Path\n","from collections import Counter\n","from typing import Dict, List\n","import torch\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForTokenClassification,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorForTokenClassification\n",")\n","from datasets import Dataset, DatasetDict\n","import numpy as np\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","try:\n","    import google.colab\n","\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False\n","\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    path_prefix = '/content/drive/MyDrive/UofT DL Term project/GreBerta-experiment-2/'\n","else:\n","    path_prefix = ''"]},{"cell_type":"markdown","source":["Fine-tune GreBerta"],"metadata":{"id":"bJZRnmkYtRsD"}},{"cell_type":"code","source":["def load_pos_data(filepath: Path) -> List[Dict]:\n","    \"\"\"Load and extract POS tagging data from alignment JSON\"\"\"\n","    with open(filepath, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    pos_data = []\n","    for verse in data['data']:\n","        tokens = [t['word'] for t in verse['greek_tokens']]\n","        pos_tags = [t['pos'] for t in verse['greek_tokens']]\n","\n","        if tokens:  # Skip empty verses\n","            pos_data.append({\n","                'tokens': tokens,\n","                'pos_tags': pos_tags,\n","                'verse_id': verse['verse_id']\n","            })\n","\n","    return pos_data\n","\n","\n","def create_label_mapping(train_data: List[Dict]) -> Dict[str, int]:\n","    \"\"\"Create mapping from POS tags to integer IDs\"\"\"\n","    all_tags = set()\n","    for example in train_data:\n","        all_tags.update(example['pos_tags'])\n","\n","    # Sort for consistency\n","    sorted_tags = sorted(all_tags)\n","    tag_to_id = {tag: i for i, tag in enumerate(sorted_tags)}\n","    id_to_tag = {i: tag for tag, i in tag_to_id.items()}\n","\n","    return tag_to_id, id_to_tag\n","\n","\n","def tokenize_and_align_labels(examples, tokenizer, tag_to_id):\n","    \"\"\"\n","    Tokenize text and align POS labels with subword tokens.\n","\n","    When a word is split into subwords (e.g., 'λόγος' -> ['λ', '##όγος']),\n","    we assign the label to the first subword and -100 to the rest (ignored in loss).\n","    \"\"\"\n","    tokenized_inputs = tokenizer(\n","        examples['tokens'],\n","        truncation=True,\n","        is_split_into_words=True,\n","        padding=False,\n","        max_length=512\n","    )\n","\n","    labels = []\n","    for i, label_list in enumerate(examples['pos_tags']):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        label_ids = []\n","        previous_word_idx = None\n","\n","        for word_idx in word_ids:\n","            # Special tokens get -100 (ignored in loss)\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            # First subword of each word gets the label\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(tag_to_id[label_list[word_idx]])\n","            # Other subwords get -100\n","            else:\n","                label_ids.append(-100)\n","\n","            previous_word_idx = word_idx\n","\n","        labels.append(label_ids)\n","\n","    tokenized_inputs['labels'] = labels\n","    return tokenized_inputs\n","\n","\n","def compute_metrics(eval_pred, id_to_tag):\n","    \"\"\"Compute accuracy and per-class metrics\"\"\"\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [id_to_tag[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [id_to_tag[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    # Flatten for metrics\n","    flat_predictions = [tag for sent in true_predictions for tag in sent]\n","    flat_labels = [tag for sent in true_labels for tag in sent]\n","\n","    accuracy = accuracy_score(flat_labels, flat_predictions)\n","\n","    return {\n","        'accuracy': accuracy,\n","        'num_examples': len(flat_labels)\n","    }\n","\n","\n","def train_pos_tagger():\n","    # Fine-tune GreBerta for POS tagging\n","    args = {\n","        'epochs': 3,  # Number of training epochs\n","        'batch_size': 16,  # Training batch size\n","        'lr': 2e-5,  # Learning rate\n","        'model_name': 'bowphs/GreBerta',  # Base model name\n","        'output_dir': path_prefix + 'pos_tagger_output', # Output directory\n","    }\n","\n","    print(\"=\" * 80)\n","    print(\"FINE-TUNING GREBERTA FOR POS TAGGING\")\n","    print(\"=\" * 80)\n","\n","    # 1. Load data\n","    print(\"\\n1. Loading data...\")\n","    train_data = load_pos_data(Path(path_prefix + 'data/train.json'))\n","    dev_data = load_pos_data(Path(path_prefix + 'data/dev.json'))\n","    test_data = load_pos_data(Path(path_prefix + 'data/test.json'))\n","\n","    print(f\"  Train: {len(train_data):,} verses\")\n","    print(f\"  Dev:   {len(dev_data):,} verses\")\n","    print(f\"  Test:  {len(test_data):,} verses\")\n","\n","    # 2. Create label mapping\n","    print(\"\\n2. Creating label mapping...\")\n","    tag_to_id, id_to_tag = create_label_mapping(train_data)\n","    num_labels = len(tag_to_id)\n","    print(f\"  Found {num_labels} POS tags:\")\n","    for tag, idx in sorted(tag_to_id.items(), key=lambda x: x[1]):\n","        # Count occurrences in train\n","        count = sum(1 for ex in train_data for t in ex['pos_tags'] if t == tag)\n","        print(f\"    {idx:2d}. {tag:5s} ({count:,} tokens)\")\n","\n","    # 3. Load tokenizer and model\n","    print(f\"\\n3. Loading {args['model_name']}...\")\n","    tokenizer = AutoTokenizer.from_pretrained(args['model_name'], add_prefix_space=True)\n","    model = AutoModelForTokenClassification.from_pretrained(\n","        args['model_name'],\n","        num_labels=num_labels,\n","        id2label=id_to_tag,\n","        label2id=tag_to_id\n","    )\n","    print(f\"  ✓ Model loaded with {num_labels} labels\")\n","    print(f\"  ✓ Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n","\n","    # 4. Create datasets\n","    print(\"\\n4. Creating Hugging Face datasets...\")\n","    train_dataset = Dataset.from_list(train_data)\n","    dev_dataset = Dataset.from_list(dev_data)\n","    test_dataset = Dataset.from_list(test_data)\n","\n","    # Tokenize\n","    print(\"  Tokenizing...\")\n","    train_dataset = train_dataset.map(\n","        lambda x: tokenize_and_align_labels(x, tokenizer, tag_to_id),\n","        batched=True,\n","        remove_columns=['tokens', 'pos_tags', 'verse_id']\n","    )\n","    dev_dataset = dev_dataset.map(\n","        lambda x: tokenize_and_align_labels(x, tokenizer, tag_to_id),\n","        batched=True,\n","        remove_columns=['tokens', 'pos_tags', 'verse_id']\n","    )\n","    test_dataset = test_dataset.map(\n","        lambda x: tokenize_and_align_labels(x, tokenizer, tag_to_id),\n","        batched=True,\n","        remove_columns=['tokens', 'pos_tags', 'verse_id']\n","    )\n","    print(f\"  ✓ Tokenized {len(train_dataset):,} training examples\")\n","\n","    # 5. Setup training\n","    print(f\"\\n5. Setting up training...\")\n","    print(f\"  Epochs: {args['epochs']}\")\n","    print(f\"  Batch size: {args['batch_size']}\")\n","    print(f\"  Learning rate: {args['lr']}\")\n","    print(f\"  Output dir: {args['output_dir']}\")\n","\n","    training_args = TrainingArguments(\n","        output_dir=args['output_dir'],\n","        learning_rate=args['lr'],\n","        per_device_train_batch_size=args['batch_size'],\n","        per_device_eval_batch_size=args['batch_size'],\n","        num_train_epochs=args['epochs'],\n","        weight_decay=0.01,\n","        eval_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"accuracy\",\n","        push_to_hub=False,\n","        logging_dir=f'{args['output_dir']}/logs',\n","        logging_steps=50,\n","        report_to=\"none\" # Added to prevent W&B login prompt\n","    )\n","\n","    data_collator = DataCollatorForTokenClassification(tokenizer)\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=dev_dataset,\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=lambda x: compute_metrics(x, id_to_tag),\n","    )\n","\n","    # 6. Train!\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"6. TRAINING STARTED\")\n","    print(\"=\" * 80)\n","\n","    train_result = trainer.train()\n","\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"TRAINING COMPLETE!\")\n","    print(\"=\" * 80)\n","    print(f\"\\nTraining metrics:\")\n","    for key, value in train_result.metrics.items():\n","        print(f\"  {key}: {value}\")\n","\n","    # 7. Evaluate on dev set\n","    print(\"\\n7. Evaluating on dev set...\")\n","    dev_results = trainer.evaluate(eval_dataset=dev_dataset)\n","    print(f\"Dev accuracy: {dev_results['eval_accuracy']:.4f}\")\n","\n","    # 8. Evaluate on test set\n","    print(\"\\n8. Evaluating on test set...\")\n","    test_results = trainer.evaluate(eval_dataset=test_dataset)\n","    print(f\"Test accuracy: {test_results['eval_accuracy']:.4f}\")\n","\n","    # 9. Save model\n","    print(f\"\\n9. Saving model to {args['output_dir']}...\")\n","    trainer.save_model(args['output_dir'])\n","    tokenizer.save_pretrained(args['output_dir'])\n","\n","    # Save label mappings\n","    import json\n","    with open(Path(args['output_dir']) / 'label_mapping.json', 'w') as f:\n","        json.dump({'tag_to_id': tag_to_id, 'id_to_tag': id_to_tag}, f, indent=2)\n","\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"✓ FINE-TUNING COMPLETE!\")\n","    print(\"=\" * 80)\n","    print(f\"\\nModel saved to: {args['output_dir']}\")\n","    print(f\"Dev accuracy:   {dev_results['eval_accuracy']:.4f}\")\n","    print(f\"Test accuracy:  {test_results['eval_accuracy']:.4f}\")\n","    print(\"\\nTo use the model:\")\n","    print(f\"  from transformers import AutoModelForTokenClassification, AutoTokenizer\")\n","    print(f\"  model = AutoModelForTokenClassification.from_pretrained('{args['output_dir']}')\")\n","    print(f\"  tokenizer = AutoTokenizer.from_pretrained('{args['output_dir']}')\")\n","    print(\"=\" * 80)\n","\n","\n","train_pos_tagger()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6e2ec1bf619a470487b6bfce3967c85e","a59899cd6ddd4aedb4391e5f8498e49c","42d763f08027471096efd5e2e1d0e8e0","64fb712b875a42cb936edf9e03592c08","c7ea2945bfef46b4a167c040b31ad2a6","7c10485db3d046c2afb6519b675eea1a","04965eea4e524da0af5cc30231188aa1","4e089997473841d8b8c6274f4c57c85e","f5740ec8cd644585b0e4c3b76ae73c62","8041789b24ef47fc9d60b45142a724c5","46bffe143a4a4a408bdb892c8d4997a4","c147e5ae9096422dbe48d468569be2ab","c8a4d03189d14485b55c7fe5c232be89","712be79adcca40eea96683fc60181f6a","1ba4d84839ff42f1b70b388b6c7565d8","8c3e3d5132ac4ab0af8679c697bed8e8","4cfe1b91ed7c43c7912b898f724a6099","807c77140df6431ba0d64604f2040ce0","a537d9e232144c7bb5695ed93f9c2418","ea13382dbde349c3a37ea1fd5fad6da9","f08ccfccf6e849479463f542b0fe9ec5","0aadc73a51584b82a57f0522175e039b","cf3226a49c5b4c0e80e631040a506dce","a276a2c94e304fe0ae2ad4a0a485c2cc","e14aceb14a6442338fbc7ee66a905491","dc2abb33d6bd416baace501d1c383807","542bf25ef0a944159c01fbff7dafa40f","d79dd9477722494a8ae08e7353a1face","59931687801a4be8926651340b56f787","ebaa75589130470fbe932da4352ad47e","1979d24963824e6f9dcc6088d3aa8412","ae78fa8f2749407a82a78e0ffe4302aa","7384ed02eb8c42e2aac2d5f03d0af411","90ecc93249614d92ab1fb56b2acc7664","d1d7115bba5f452cb149ccfffbeef6db","1106c4aeccb148f192d8d5420bd6a669","0d4265670d29490d979b54ded50c3c3c","4184764c38f9461f9fd09d26650e4e4e","642b7760027546468fb75cedfdfed316","98c87fe9196d4c61a782aaad1eab1883","3514464f12a94fdea873fee293f1d983","85d90feabb2545bbb94ce1570ec52311","f62ca3e40a484d1ab743a696ab701e60","553a287a08464079bb944467c9d532fa","5dfd451ff56140b794eaeb31c46b1627","1b6c7278dc264cd0add7acab42350a03","4041a15485714e7a9eb565b72d87a8c5","bbb3e8804a324b7ab56363af25c2118c","c4e11f691ecb4052a0116e601562c8c6","3dd4788ab80b4a42934450794538d979","3433ed00e8804dfe8a567bc5aeb0f802","cc75e721371c49adbe6fe89c51640445","87e3b90c2b3748749339c19e0e98f049","ba1e0e927da94a57ae75bf2a3acf1d3a","813c2f7c28a74e6ca772c1a8acf77954","394ae7209e594146a4f88fdd846be526","ca75ab7864fe4276813b53566e3da7ff","121d386328d44925b713e16e71805a26","3b95ad29ada54ad2b0cb9c533609be47","0ff3d3fb55bd404081a98d8112b4a0d9","b4c55ccaa7014af287741367b83dd2ff","b976cb7b269145e28e1e340ac02e12ad","d233648bd5ea49b6badec5c87f5f64fe","425e7e182adb4160b51e30237f63f782","05d4f619c4424da58b52a2307b85394b","feb0459de9bc49abaa4743b18ff0ca5a","65a731e81315400d85e6899244cd74b5","a54caddc2e6843188968f3d0b6c0d595","853b1f5b98f144aa999301f575d906d6","7062adc0d4304ede8726e7542785723a","a1ada5cebc2b4767bb2317905ed6581f","21378c829dea4e52b3b311c067266c14","77c22670f00f4abd9f233b5a060c9d23","cc1fa0e6f6bc4384b6d4f2470c516043","82db7ba30e344bc897ef55d558d07ae8","79baf8dcda9c412b9a59c0eb98eed52a","f87f0e117f4d413eb48e56e8a73926fc","08fd142b5817460d9860daf845f72e51","ae6fcbb7efcf40fead5a8e7057855f01","fce7f385cfac49ab85cd1c742a503cec","191136443976415cb6459371b884e0ae","536fcf612b744f2fa87eb187c7824533","963172884d294346b812f5debaa1368c","bd54b7ac5b7240bcba797f3e926e6637","a19b8b030c524e578a5510d13cce30e5","fa118409bd684688b095a33dbe2dda4f","a0958582961a4f64b2bd0da7915cbfb3","4ce69e0452ce42fdb001a215ba16e12a","d01ee2e63170474493de932c2acc3b39","d68210cf953740d5b6c6f628a18cdddf","07a073c138af45938659fb7096bd013f","5f3b3887ae7a43a6bef2767601518dc8","58eb0faa060e47869097c7f75ebd7d64","cd056bc055864559819ff8ccf666fe35","8007f2c4211f41099e49d0cf08366afc","ed2b1085254f40ea8f80547a8fb0f834","7e705c6445b24090972d6a7b1e128013","bb4e02c445344ecebe4dd7610720aa11","a3411c1e90fe4ee980e69c4bf7385370","6acebfd5832745dea2e219e71c2fd896","fb14f7ae79b54257bfe6ec6c6357fc5b","7fb2dfc6ec1f45a98b9113834d1e87ba","86a22728b25f4f659f3d40e7e5906d2e","a4f985ee2f0d4791a63360532cdbf52c","860f9dc1a66544bcb56944f477397bf1","2ad0fc1cc1844dfaa874efbf09037bba","abe1582e08aa46ee997a065f82d60b7f","aa95a7a19d094b16b71b3714c5265b76","4fdf241be3e842b59109ae7a21035e93","a3be8b0bfa58422c93db16f9b537053b"]},"id":"1J2LGpimtVYN","executionInfo":{"status":"ok","timestamp":1763415942797,"user_tz":300,"elapsed":139097,"user":{"displayName":"Arjun G. Menon","userId":"13198646079844385927"}},"outputId":"aa8182f1-5510-451d-f2c8-26412db39e28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","FINE-TUNING GREBERTA FOR POS TAGGING\n","================================================================================\n","\n","1. Loading data...\n","  Train: 7,198 verses\n","  Dev:   284 verses\n","  Test:  443 verses\n","\n","2. Creating label mapping...\n","  Found 13 POS tags:\n","     0. A-    (7,860 tokens)\n","     1. C-    (16,112 tokens)\n","     2. D-    (5,655 tokens)\n","     3. I-    (15 tokens)\n","     4. N-    (24,573 tokens)\n","     5. P-    (9,662 tokens)\n","     6. RA    (17,088 tokens)\n","     7. RD    (1,579 tokens)\n","     8. RI    (1,102 tokens)\n","     9. RP    (10,446 tokens)\n","    10. RR    (1,490 tokens)\n","    11. V-    (25,398 tokens)\n","    12. X-    (905 tokens)\n","\n","3. Loading bowphs/GreBerta...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e2ec1bf619a470487b6bfce3967c85e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c147e5ae9096422dbe48d468569be2ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf3226a49c5b4c0e80e631040a506dce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ecc93249614d92ab1fb56b2acc7664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dfd451ff56140b794eaeb31c46b1627"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/675 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"394ae7209e594146a4f88fdd846be526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/504M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65a731e81315400d85e6899244cd74b5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at bowphs/GreBerta and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["  ✓ Model loaded with 13 labels\n","  ✓ Model has 125,397,517 parameters\n","\n","4. Creating Hugging Face datasets...\n","  Tokenizing...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/7198 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08fd142b5817460d9860daf845f72e51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/284 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d01ee2e63170474493de932c2acc3b39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/443 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6acebfd5832745dea2e219e71c2fd896"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  ✓ Tokenized 7,198 training examples\n","\n","5. Setting up training...\n","  Epochs: 3\n","  Batch size: 16\n","  Learning rate: 2e-05\n","  Output dir: /content/drive/MyDrive/UofT DL Term project/GreBerta-experiment-2/pos_tagger_output\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4107149067.py:199: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","6. TRAINING STARTED\n","================================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1350/1350 01:47, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Num Examples</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.040500</td>\n","      <td>0.047780</td>\n","      <td>0.987786</td>\n","      <td>5158</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.023600</td>\n","      <td>0.034769</td>\n","      <td>0.988561</td>\n","      <td>5158</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.012700</td>\n","      <td>0.035012</td>\n","      <td>0.990500</td>\n","      <td>5158</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","TRAINING COMPLETE!\n","================================================================================\n","\n","Training metrics:\n","  train_runtime: 109.1574\n","  train_samples_per_second: 197.824\n","  train_steps_per_second: 12.367\n","  total_flos: 429776895059172.0\n","  train_loss: 0.09515314415649131\n","  epoch: 3.0\n","\n","7. Evaluating on dev set...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='46' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18/18 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dev accuracy: 0.9905\n","\n","8. Evaluating on test set...\n","Test accuracy: 0.9928\n","\n","9. Saving model to /content/drive/MyDrive/UofT DL Term project/GreBerta-experiment-2/pos_tagger_output...\n","\n","================================================================================\n","✓ FINE-TUNING COMPLETE!\n","================================================================================\n","\n","Model saved to: /content/drive/MyDrive/UofT DL Term project/GreBerta-experiment-2/pos_tagger_output\n","Dev accuracy:   0.9905\n","Test accuracy:  0.9928\n","\n","To use the model:\n","  from transformers import AutoModelForTokenClassification, AutoTokenizer\n","  model = AutoModelForTokenClassification.from_pretrained('/content/drive/MyDrive/UofT DL Term project/GreBerta-experiment-2/pos_tagger_output')\n","  tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/UofT DL Term project/GreBerta-experiment-2/pos_tagger_output')\n","================================================================================\n"]}]},{"cell_type":"markdown","source":["Word Alignment"],"metadata":{"id":"vfGwInl20cn-"}},{"cell_type":"markdown","source":[],"metadata":{"id":"CQPZtAwls24w"}},{"cell_type":"code","source":["import json\n","import argparse\n","import random\n","from pathlib import Path\n","from typing import Dict, List, Tuple\n","from dataclasses import dataclass\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModel,\n","    get_linear_schedule_with_warmup\n",")\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.metrics import precision_recall_fscore_support, classification_report\n","\n","@dataclass\n","class AlignmentExample:\n","    \"\"\"Single verse with alignment pairs\"\"\"\n","    verse_id: str\n","    greek_tokens: List[str]\n","    english_tokens: List[str]\n","    alignments: List[Tuple[int, int]]  # (greek_idx, english_idx) pairs\n","\n","\n","class AlignmentModel(nn.Module):\n","    \"\"\"Cross-lingual word alignment model\"\"\"\n","\n","    def __init__(self, greek_model_name='bowphs/GreBerta',\n","                 english_model_name='bert-base-uncased',\n","                 hidden_dim=256):\n","        super().__init__()\n","\n","        # Encoders\n","        self.greek_encoder = AutoModel.from_pretrained(greek_model_name)\n","        self.english_encoder = AutoModel.from_pretrained(english_model_name)\n","\n","        # Get hidden sizes\n","        greek_hidden = self.greek_encoder.config.hidden_size\n","        english_hidden = self.english_encoder.config.hidden_size\n","\n","        # Classification head\n","        self.classifier = nn.Sequential(\n","            nn.Linear(greek_hidden + english_hidden, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(hidden_dim, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(128, 2)  # Binary: aligned or not\n","        )\n","\n","    def forward(self, greek_input_ids, greek_attention_mask,\n","                english_input_ids, english_attention_mask,\n","                greek_indices, english_indices):\n","        \"\"\"\n","        Args:\n","            greek_input_ids: [batch_size, max_greek_len]\n","            greek_attention_mask: [batch_size, max_greek_len]\n","            english_input_ids: [batch_size, max_english_len]\n","            english_attention_mask: [batch_size, max_english_len]\n","            greek_indices: [batch_size, num_pairs] - which Greek token for each pair\n","            english_indices: [batch_size, num_pairs] - which English token for each pair\n","\n","        Returns:\n","            logits: [batch_size, num_pairs, 2] - alignment scores\n","        \"\"\"\n","        # Encode Greek\n","        greek_outputs = self.greek_encoder(\n","            input_ids=greek_input_ids,\n","            attention_mask=greek_attention_mask\n","        )\n","        greek_embeddings = greek_outputs.last_hidden_state  # [batch, greek_len, hidden]\n","\n","        # Encode English\n","        english_outputs = self.english_encoder(\n","            input_ids=english_input_ids,\n","            attention_mask=english_attention_mask\n","        )\n","        english_embeddings = english_outputs.last_hidden_state  # [batch, eng_len, hidden]\n","\n","        # Gather embeddings for specified pairs\n","        batch_size, num_pairs = greek_indices.shape\n","\n","        # Get Greek embeddings for each pair\n","        greek_pair_embeddings = torch.gather(\n","            greek_embeddings,\n","            dim=1,\n","            index=greek_indices.unsqueeze(-1).expand(-1, -1, greek_embeddings.size(-1))\n","        )  # [batch, num_pairs, greek_hidden]\n","\n","        # Get English embeddings for each pair\n","        english_pair_embeddings = torch.gather(\n","            english_embeddings,\n","            dim=1,\n","            index=english_indices.unsqueeze(-1).expand(-1, -1, english_embeddings.size(-1))\n","        )  # [batch, num_pairs, english_hidden]\n","\n","        # Concatenate embeddings\n","        combined = torch.cat([greek_pair_embeddings, english_pair_embeddings], dim=-1)\n","\n","        # Classify each pair\n","        logits = self.classifier(combined)  # [batch, num_pairs, 2]\n","\n","        return logits\n","\n","\n","class AlignmentDataset(Dataset):\n","    \"\"\"Dataset for word alignment training\"\"\"\n","\n","    def __init__(self, examples: List[AlignmentExample],\n","                 greek_tokenizer, english_tokenizer,\n","                 max_pairs_per_verse=50):\n","        self.examples = examples\n","        self.greek_tokenizer = greek_tokenizer\n","        self.english_tokenizer = english_tokenizer\n","        self.max_pairs_per_verse = max_pairs_per_verse\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, idx):\n","        example = self.examples[idx]\n","\n","        # Tokenize Greek (join with spaces)\n","        greek_text = ' '.join(example.greek_tokens)\n","        greek_encoded = self.greek_tokenizer(\n","            greek_text,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors='pt'\n","        )\n","\n","        # Tokenize English\n","        english_text = ' '.join(example.english_tokens)\n","        english_encoded = self.english_tokenizer(\n","            english_text,\n","            truncation=True,\n","            max_length=512,\n","            return_tensors='pt'\n","        )\n","\n","        # Map original word indices to subword indices\n","        greek_word_to_token = self._get_word_to_token_map(\n","            example.greek_tokens, greek_encoded\n","        )\n","        english_word_to_token = self._get_word_to_token_map(\n","            example.english_tokens, english_encoded\n","        )\n","\n","        # Create training pairs\n","        # Positive examples: actual alignments\n","        positive_pairs = []\n","        for greek_idx, english_idx in example.alignments:\n","            if greek_idx in greek_word_to_token and english_idx in english_word_to_token:\n","                positive_pairs.append((\n","                    greek_word_to_token[greek_idx],\n","                    english_word_to_token[english_idx],\n","                    1  # label: aligned\n","                ))\n","\n","        # Negative examples: random non-aligned pairs\n","        num_negatives = min(len(positive_pairs) * 2, self.max_pairs_per_verse)\n","        negative_pairs = []\n","\n","        all_greek_indices = list(greek_word_to_token.values())\n","        all_english_indices = list(english_word_to_token.values())\n","\n","        # Create set of positive pairs for fast lookup\n","        positive_set = {(g, e) for g, e, _ in positive_pairs}\n","\n","        attempts = 0\n","        while len(negative_pairs) < num_negatives and attempts < num_negatives * 10:\n","            g_idx = random.choice(all_greek_indices)\n","            e_idx = random.choice(all_english_indices)\n","            if (g_idx, e_idx) not in positive_set:\n","                negative_pairs.append((g_idx, e_idx, 0))  # label: not aligned\n","            attempts += 1\n","\n","        # Combine and shuffle\n","        all_pairs = positive_pairs + negative_pairs\n","        random.shuffle(all_pairs)\n","\n","        # Limit total pairs\n","        all_pairs = all_pairs[:self.max_pairs_per_verse]\n","\n","        if not all_pairs:\n","            # Create dummy pair if no valid pairs\n","            all_pairs = [(1, 1, 0)]\n","\n","        greek_indices = torch.tensor([p[0] for p in all_pairs], dtype=torch.long)\n","        english_indices = torch.tensor([p[1] for p in all_pairs], dtype=torch.long)\n","        labels = torch.tensor([p[2] for p in all_pairs], dtype=torch.long)\n","\n","        return {\n","            'greek_input_ids': greek_encoded['input_ids'].squeeze(0),\n","            'greek_attention_mask': greek_encoded['attention_mask'].squeeze(0),\n","            'english_input_ids': english_encoded['input_ids'].squeeze(0),\n","            'english_attention_mask': english_encoded['attention_mask'].squeeze(0),\n","            'greek_indices': greek_indices,\n","            'english_indices': english_indices,\n","            'labels': labels,\n","            'verse_id': example.verse_id\n","        }\n","\n","    def _get_word_to_token_map(self, words, encoded):\n","        \"\"\"Map word indices to their first subword token index\"\"\"\n","        word_to_token = {}\n","        word_ids = encoded.word_ids()\n","\n","        for token_idx, word_idx in enumerate(word_ids):\n","            if word_idx is not None and word_idx not in word_to_token:\n","                word_to_token[word_idx] = token_idx\n","\n","        return word_to_token\n","\n","\n","def collate_fn(batch):\n","    \"\"\"Custom collate function for batching\"\"\"\n","    # Find max lengths\n","    max_greek_len = max(item['greek_input_ids'].size(0) for item in batch)\n","    max_english_len = max(item['english_input_ids'].size(0) for item in batch)\n","    max_pairs = max(item['labels'].size(0) for item in batch)\n","\n","    # Pad everything\n","    greek_input_ids = []\n","    greek_attention_mask = []\n","    english_input_ids = []\n","    english_attention_mask = []\n","    greek_indices = []\n","    english_indices = []\n","    labels = []\n","    verse_ids = []\n","\n","    for item in batch:\n","        # Pad Greek\n","        g_len = item['greek_input_ids'].size(0)\n","        greek_input_ids.append(\n","            torch.cat([item['greek_input_ids'],\n","                      torch.zeros(max_greek_len - g_len, dtype=torch.long)])\n","        )\n","        greek_attention_mask.append(\n","            torch.cat([item['greek_attention_mask'],\n","                      torch.zeros(max_greek_len - g_len, dtype=torch.long)])\n","        )\n","\n","        # Pad English\n","        e_len = item['english_input_ids'].size(0)\n","        english_input_ids.append(\n","            torch.cat([item['english_input_ids'],\n","                      torch.zeros(max_english_len - e_len, dtype=torch.long)])\n","        )\n","        english_attention_mask.append(\n","            torch.cat([item['english_attention_mask'],\n","                      torch.zeros(max_english_len - e_len, dtype=torch.long)])\n","        )\n","\n","        # Pad pairs\n","        num_pairs = item['labels'].size(0)\n","        greek_indices.append(\n","            torch.cat([item['greek_indices'],\n","                      torch.zeros(max_pairs - num_pairs, dtype=torch.long)])\n","        )\n","        english_indices.append(\n","            torch.cat([item['english_indices'],\n","                      torch.zeros(max_pairs - num_pairs, dtype=torch.long)])\n","        )\n","        labels.append(\n","            torch.cat([item['labels'],\n","                      torch.full((max_pairs - num_pairs,), -100, dtype=torch.long)])  # -100 = ignore\n","        )\n","\n","        verse_ids.append(item['verse_id'])\n","\n","    return {\n","        'greek_input_ids': torch.stack(greek_input_ids),\n","        'greek_attention_mask': torch.stack(greek_attention_mask),\n","        'english_input_ids': torch.stack(english_input_ids),\n","        'english_attention_mask': torch.stack(english_attention_mask),\n","        'greek_indices': torch.stack(greek_indices),\n","        'english_indices': torch.stack(english_indices),\n","        'labels': torch.stack(labels),\n","        'verse_ids': verse_ids\n","    }\n","\n","\n","def load_alignment_data(filepath: Path) -> List[AlignmentExample]:\n","    \"\"\"Load alignment data from JSON\"\"\"\n","    with open(filepath, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    examples = []\n","    for verse in data['data']:\n","        if not verse['alignments']:\n","            continue\n","\n","        greek_tokens = [t['word'] for t in verse['greek_tokens']]\n","        english_tokens = [t['word'] for t in verse['english_tokens']]\n","        alignments = [(a['greek_idx'], a['english_idx'])\n","                     for a in verse['alignments']]\n","\n","        examples.append(AlignmentExample(\n","            verse_id=verse['verse_id'],\n","            greek_tokens=greek_tokens,\n","            english_tokens=english_tokens,\n","            alignments=alignments\n","        ))\n","\n","    return examples\n","\n","\n","def train_epoch(model, dataloader, optimizer, scheduler, device):\n","    \"\"\"Train for one epoch\"\"\"\n","    model.train()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    progress_bar = tqdm(dataloader, desc='Training')\n","\n","    for batch in progress_bar:\n","        # Move to device\n","        greek_input_ids = batch['greek_input_ids'].to(device)\n","        greek_attention_mask = batch['greek_attention_mask'].to(device)\n","        english_input_ids = batch['english_input_ids'].to(device)\n","        english_attention_mask = batch['english_attention_mask'].to(device)\n","        greek_indices = batch['greek_indices'].to(device)\n","        english_indices = batch['english_indices'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        # Forward pass\n","        logits = model(\n","            greek_input_ids, greek_attention_mask,\n","            english_input_ids, english_attention_mask,\n","            greek_indices, english_indices\n","        )\n","\n","        # Compute loss (only on valid pairs)\n","        loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n","        loss = loss_fn(logits.view(-1, 2), labels.view(-1))\n","\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","\n","        # Track metrics\n","        total_loss += loss.item()\n","\n","        # Get predictions\n","        preds = torch.argmax(logits, dim=-1)\n","        valid_mask = labels != -100\n","        all_preds.extend(preds[valid_mask].cpu().numpy())\n","        all_labels.extend(labels[valid_mask].cpu().numpy())\n","\n","        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n","\n","    # Compute metrics\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        all_labels, all_preds, average='binary'\n","    )\n","\n","    return {\n","        'loss': total_loss / len(dataloader),\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","\n","def evaluate(model, dataloader, device):\n","    \"\"\"Evaluate model\"\"\"\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc='Evaluating'):\n","            greek_input_ids = batch['greek_input_ids'].to(device)\n","            greek_attention_mask = batch['greek_attention_mask'].to(device)\n","            english_input_ids = batch['english_input_ids'].to(device)\n","            english_attention_mask = batch['english_attention_mask'].to(device)\n","            greek_indices = batch['greek_indices'].to(device)\n","            english_indices = batch['english_indices'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            logits = model(\n","                greek_input_ids, greek_attention_mask,\n","                english_input_ids, english_attention_mask,\n","                greek_indices, english_indices\n","            )\n","\n","            preds = torch.argmax(logits, dim=-1)\n","            valid_mask = labels != -100\n","            all_preds.extend(preds[valid_mask].cpu().numpy())\n","            all_labels.extend(labels[valid_mask].cpu().numpy())\n","\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        all_labels, all_preds, average='binary'\n","    )\n","\n","    return {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","\n","def train_alignment():\n","    args = {\n","        'epochs': 3,\n","        'batch_size': 8,\n","        'lr': 2e-5,\n","        'output_dir': path_prefix+'alignment_model_output_colab'\n","    }\n","\n","    print(\"=\" * 80)\n","    print(\"TRAINING WORD ALIGNMENT MODEL\")\n","    print(\"=\" * 80)\n","\n","    # Device\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f\"\\nUsing device: {device}\")\n","\n","    # Load data\n","    print(\"\\n1. Loading data...\")\n","    train_examples = load_alignment_data(Path(path_prefix+'data/train.json'))\n","    dev_examples = load_alignment_data(Path(path_prefix+'data/dev.json'))\n","    test_examples = load_alignment_data(Path(path_prefix+'data/test.json'))\n","\n","    print(f\"  Train: {len(train_examples):,} verses with alignments\")\n","    print(f\"  Dev:   {len(dev_examples):,} verses\")\n","    print(f\"  Test:  {len(test_examples):,} verses\")\n","\n","    # Load tokenizers\n","    print(\"\\n2. Loading tokenizers...\")\n","    greek_tokenizer = AutoTokenizer.from_pretrained('bowphs/GreBerta')\n","    english_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","    print(\"  ✓ Tokenizers loaded\")\n","\n","    # Create datasets\n","    print(\"\\n3. Creating datasets...\")\n","    train_dataset = AlignmentDataset(train_examples, greek_tokenizer, english_tokenizer)\n","    dev_dataset = AlignmentDataset(dev_examples, greek_tokenizer, english_tokenizer)\n","    test_dataset = AlignmentDataset(test_examples, greek_tokenizer, english_tokenizer)\n","\n","    train_dataloader = DataLoader(\n","        train_dataset, batch_size=args['batch_size'],\n","        shuffle=True, collate_fn=collate_fn\n","    )\n","    dev_dataloader = DataLoader(\n","        dev_dataset, batch_size=args['batch_size'],\n","        shuffle=False, collate_fn=collate_fn\n","    )\n","    test_dataloader = DataLoader(\n","        test_dataset, batch_size=args['batch_size'],\n","        shuffle=False, collate_fn=collate_fn\n","    )\n","\n","    print(f\"  ✓ Created {len(train_dataloader):,} training batches\")\n","\n","    # Create model\n","    print(\"\\n4. Creating model...\")\n","    model = AlignmentModel()\n","    model = model.to(device)\n","\n","    total_params = sum(p.numel() for p in model.parameters())\n","    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"  ✓ Model created\")\n","    print(f\"  Total parameters: {total_params:,}\")\n","    print(f\"  Trainable parameters: {trainable_params:,}\")\n","\n","    # Setup training\n","    print(\"\\n5. Setting up training...\")\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=args['lr'])\n","    num_training_steps = len(train_dataloader) * args['epochs']\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=num_training_steps // 10,\n","        num_training_steps=num_training_steps\n","    )\n","\n","    print(f\"  Epochs: {args['epochs']}\")\n","    print(f\"  Batch size: {args['batch_size']}\")\n","    print(f\"  Learning rate: {args['lr']}\")\n","    print(f\"  Output dir: {args['output_dir']}\")\n","\n","    # Train!\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"6. TRAINING STARTED\")\n","    print(\"=\" * 80)\n","\n","    best_f1 = 0\n","    for epoch in range(args['epochs']):\n","        print(f\"\\nEpoch {epoch + 1}/{args['epochs']}\")\n","        print(\"-\" * 80)\n","\n","        # Train\n","        train_metrics = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n","        print(f\"Train - Loss: {train_metrics['loss']:.4f}, \"\n","              f\"P: {train_metrics['precision']:.4f}, \"\n","              f\"R: {train_metrics['recall']:.4f}, \"\n","              f\"F1: {train_metrics['f1']:.4f}\")\n","\n","        # Evaluate\n","        dev_metrics = evaluate(model, dev_dataloader, device)\n","        print(f\"Dev   - P: {dev_metrics['precision']:.4f}, \"\n","              f\"R: {dev_metrics['recall']:.4f}, \"\n","              f\"F1: {dev_metrics['f1']:.4f}\")\n","\n","        # Save best model\n","        if dev_metrics['f1'] > best_f1:\n","            best_f1 = dev_metrics['f1']\n","            output_dir = Path(args['output_dir'])\n","            output_dir.mkdir(exist_ok=True)\n","            torch.save(model.state_dict(), output_dir / 'best_model.pt')\n","            print(f\"  ✓ Saved best model (F1: {best_f1:.4f})\")\n","\n","    # Final evaluation\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"7. FINAL EVALUATION\")\n","    print(\"=\" * 80)\n","\n","    # Load best model\n","    model.load_state_dict(torch.load(Path(args['output_dir']) / 'best_model.pt'))\n","\n","    print(\"\\nDev set:\")\n","    dev_metrics = evaluate(model, dev_dataloader, device)\n","    print(f\"  Precision: {dev_metrics['precision']:.4f}\")\n","    print(f\"  Recall:    {dev_metrics['recall']:.4f}\")\n","    print(f\"  F1 Score:  {dev_metrics['f1']:.4f}\")\n","\n","    print(\"\\nTest set:\")\n","    test_metrics = evaluate(model, test_dataloader, device)\n","    print(f\"  Precision: {test_metrics['precision']:.4f}\")\n","    print(f\"  Recall:    {test_metrics['recall']:.4f}\")\n","    print(f\"  F1 Score:  {test_metrics['f1']:.4f}\")\n","\n","    # Save final artifacts\n","    print(f\"\\n8. Saving model and tokenizers...\")\n","    output_dir = Path(args['output_dir'])\n","    output_dir.mkdir(exist_ok=True)\n","\n","    torch.save(model.state_dict(), output_dir / 'model.pt')\n","    greek_tokenizer.save_pretrained(output_dir / 'greek_tokenizer')\n","    english_tokenizer.save_pretrained(output_dir / 'english_tokenizer')\n","\n","    # Save config\n","    config = {\n","        'greek_model': 'bowphs/GreBerta',\n","        'english_model': 'bert-base-uncased',\n","        'dev_f1': dev_metrics['f1'],\n","        'test_f1': test_metrics['f1'],\n","    }\n","    with open(output_dir / 'config.json', 'w') as f:\n","        json.dump(config, f, indent=2)\n","\n","    print(\"\\n\" + \"=\" * 80)\n","    print(\"✓ TRAINING COMPLETE!\")\n","    print(\"=\" * 80)\n","    print(f\"\\nModel saved to: {args['output_dir']}\")\n","    print(f\"Test F1 Score: {test_metrics['f1']:.4f}\")\n","    print(\"\\nTo use the model, see test_alignment.py\")\n","    print(\"=\" * 80)\n","\n","\n","train_alignment()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_I56L20U0Z3O","executionInfo":{"status":"ok","timestamp":1763417753224,"user_tz":300,"elapsed":518255,"user":{"displayName":"Arjun G. Menon","userId":"13198646079844385927"}},"outputId":"9c1750d5-a90c-416a-eda5-83a7c45b4878"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","TRAINING WORD ALIGNMENT MODEL\n","================================================================================\n","\n","Using device: cuda\n","\n","1. Loading data...\n","  Train: 5,846 verses with alignments\n","  Dev:   284 verses\n","  Test:  380 verses\n","\n","2. Loading tokenizers...\n","  ✓ Tokenizers loaded\n","\n","3. Creating datasets...\n","  ✓ Created 731 training batches\n","\n","4. Creating model...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at bowphs/GreBerta and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["  ✓ Model created\n","  Total parameters: 235,886,978\n","  Trainable parameters: 235,886,978\n","\n","5. Setting up training...\n","  Epochs: 3\n","  Batch size: 8\n","  Learning rate: 2e-05\n","  Output dir: /content/drive/MyDrive/UofT DL Term project/GreBerta-experiment-2/alignment_model_output_colab\n","\n","================================================================================\n","6. TRAINING STARTED\n","================================================================================\n","\n","Epoch 1/3\n","--------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 731/731 [02:44<00:00,  4.45it/s, loss=0.3639]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.4655, P: 0.7482, R: 0.5743, F1: 0.6498\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 36/36 [00:00<00:00, 39.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Dev   - P: 0.7770, R: 0.7843, F1: 0.7806\n","  ✓ Saved best model (F1: 0.7806)\n","\n","Epoch 2/3\n","--------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 731/731 [02:45<00:00,  4.41it/s, loss=0.2221]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.2964, P: 0.8195, R: 0.8487, F1: 0.8338\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 36/36 [00:00<00:00, 39.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Dev   - P: 0.8122, R: 0.8456, F1: 0.8286\n","  ✓ Saved best model (F1: 0.8286)\n","\n","Epoch 3/3\n","--------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 731/731 [02:44<00:00,  4.43it/s, loss=0.2497]\n"]},{"output_type":"stream","name":"stdout","text":["Train - Loss: 0.2486, P: 0.8485, R: 0.8846, F1: 0.8662\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 36/36 [00:00<00:00, 38.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Dev   - P: 0.8337, R: 0.8552, F1: 0.8443\n","  ✓ Saved best model (F1: 0.8443)\n","\n","================================================================================\n","7. FINAL EVALUATION\n","================================================================================\n","\n","Dev set:\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 36/36 [00:00<00:00, 38.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["  Precision: 0.8390\n","  Recall:    0.8619\n","  F1 Score:  0.8503\n","\n","Test set:\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 48/48 [00:01<00:00, 31.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["  Precision: 0.8835\n","  Recall:    0.9108\n","  F1 Score:  0.8969\n","\n","8. Saving model and tokenizers...\n","\n","================================================================================\n","✓ TRAINING COMPLETE!\n","================================================================================\n","\n","Model saved to: /content/drive/MyDrive/UofT DL Term project/GreBerta-experiment-2/alignment_model_output_colab\n","Test F1 Score: 0.8969\n","\n","To use the model, see test_alignment.py\n","================================================================================\n"]}]}]}